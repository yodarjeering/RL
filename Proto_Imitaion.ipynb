{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bbedb4-399e-4c95-a9bd-f8653999ad1a",
   "metadata": {},
   "source": [
    "# import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe8e0446-8dd4-4933-91fc-c0178688bb65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from collections import namedtuple\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from collections import namedtuple\n",
    "from collections import deque\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "# from mylibrary.fnframework import FNAgent,Environment,Action,Trainer\n",
    "# from mylibrary.plottrade import PlotTrade\n",
    "# from mylibrary.maketraindata import MakeTrainData\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score  \n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.action_chains import ActionChains\n",
    "from tensorflow.python.keras.models import load_model\n",
    "import statsmodels.graphics.api as smg\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from scipy import stats\n",
    "from scipy.stats import f\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report, accuracy_score,roc_curve, roc_auc_score\n",
    "import pickle\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd332098-8954-4a15-9e8f-0d379ed0e2a7",
   "metadata": {},
   "source": [
    "# path ubu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef960622-cf70-40ed-b893-aaaed713ea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_daw = '/home/hipro/デスクトップ/StockPriceData/Stock_index/DAW_10years.csv'\n",
    "path_tpx = '/home/hipro/デスクトップ/StockPriceData/Stock_index/TOPIX_10years.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de8fd4-a3da-45b9-814a-69a49e467c3b",
   "metadata": {},
   "source": [
    "# path mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867f1471-2e5a-4be2-9b6b-40e2d4291cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_tpx = '/Users/rince/Desktop/StockPriceData/Stock_index/TOPIX_10years.csv'\n",
    "path_225 = '/Users/rince/Desktop/StockPriceData/Stock_index/NK225_10years.csv'\n",
    "path_daw = '/Users/rince/Desktop/StockPriceData/Stock_index/DAW_10years.csv'\n",
    "path_bear = '/Users/rince/Desktop/StockPriceData/Stock_index/R225BEAR_10years.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc97456b-d953-45fc-be22-94ab1d0c2272",
   "metadata": {},
   "source": [
    "# path win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9fa313-39f1-4353-ad15-7830c4b4b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tpx = '/Users/Owner/Desktop/StockPriceData/Stock_index/TOPIX_10years.csv'\n",
    "path_225 = '/Users/Owner/Desktop/StockPriceData/Stock_index/NK225_10years.csv'\n",
    "path_daw = '/Users/Owner/Desktop/StockPriceData/Stock_index/DAW_10years.csv'\n",
    "path_bear = '/Users/Owner/Desktop/StockPriceData/Stock_index/R225BEAR_10years.csv'\n",
    "\n",
    "path_tpx_sim = '/Users/Owner/Desktop/StockPriceData/TOPIX/TOPIX_20211208.csv'\n",
    "path_daw_sim = '/Users/Owner/Desktop/StockPriceData/DAW/DAW_20211208.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4b23c-a53b-497e-a66c-b35dd9f47f73",
   "metadata": {},
   "source": [
    "# funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c8d827e-205f-4645-814c-417353aee53e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgb_pred(x_train, y_train, x_test, y_test):\n",
    "    param_dist = {'objective':'binary:logistic', 'n_estimators':16,'use_label_encoder':False,\n",
    "                 'max_depth':4}\n",
    "    \n",
    "    param_def = {'objective':'binary:logistic','use_label_encoder':False}\n",
    "    xgb_model = xgb.XGBClassifier(**param_dist)\n",
    "    hr_pred = xgb_model.fit(x_train.astype(float), np.array(y_train), eval_metric='logloss').predict(x_test.astype(float))\n",
    "    print(\"---------------------\")\n",
    "    y_proba_train = xgb_model.predict_proba(x_train)[:,1]\n",
    "    y_proba = xgb_model.predict_proba(x_test)[:,1]\n",
    "    print('AUC train:',roc_auc_score(y_train,y_proba_train))    \n",
    "    print('AUC test :',roc_auc_score(y_test,y_proba))\n",
    "    print(classification_report(np.array(y_test), hr_pred))\n",
    "    xgb.plot_importance(xgb_model) \n",
    "    return xgb_model\n",
    "\n",
    "def for_xgb_data(path_tpx, path_daw):\n",
    "    df_tpx = DataFramePreProcessing(path_tpx).load_df()\n",
    "    df_daw = DataFramePreProcessing(path_daw,is_daw=True).load_df()\n",
    "    daw_p = df_daw.pct_change()\n",
    "    df_con = pd.concat([daw_p,df_tpx],axis = 1,join='inner').astype(float)\n",
    "    df_tmp = df_con.drop(df_con[ df_con['volume']==0].index)\n",
    "    return df_tmp\n",
    "\n",
    "def make_x_train(path_tpx, path_daw):\n",
    "    df_tpx  = DataFramePreProcessing(path_tpx).load_df()\n",
    "    df_daw = DataFramePreProcessing(path_daw, is_daw=True).load_df()\n",
    "    daw_p = df_daw['dclose'].pct_change()\n",
    "    tpx_p = df_tpx['close'].pct_change()\n",
    "\n",
    "    df_con = pd.concat([daw_p,tpx_p],axis = 1,join='inner').astype(float)\n",
    "    df_tmp = df_con.rename(columns={'close': 'pclose'})\n",
    "    df_tmp = pd.concat([df_tmp,df_tpx['close']],axis = 1,join='inner').astype(float)\n",
    "\n",
    "    x_train = df_tmp.loc[:,['dclose','pclose']].iloc[1:]\n",
    "    price_chart = df_tmp['close'].iloc[1:]\n",
    "    return x_train, price_chart\n",
    "\n",
    "def make_x_train2(state_, chart_, path_tpx, path_daw):\n",
    "    df_state = pd.DataFrame(state_)\n",
    "    df_state['day'] = chart_.index\n",
    "    df_state.reset_index(inplace=True)\n",
    "    df_state.set_index('day',inplace=True)\n",
    "    df_state.drop('index',axis=1,inplace=True)\n",
    "    \n",
    "    x_train, _ = make_x_train(path_tpx, path_daw)\n",
    "    x_train = pd.concat([x_train,df_state],axis = 1,join='inner').astype(float)\n",
    "    \n",
    "    return x_train, chart_\n",
    "\n",
    "def predict_tomorrow(lq,folder_name):\n",
    "    path_ = '/Users/rince/Desktop/StockPriceData/%s/*.csv' % folder_name\n",
    "    file = glob.glob(path_)\n",
    "    path_tpx = sorted(file)[-1]\n",
    "    path_ = '/Users/rince/Desktop/StockPriceData/DAW/*.csv'\n",
    "    file = glob.glob(path_)\n",
    "    path_daw = sorted(file)[-1]\n",
    "    lq.predict_tomorrow(path_tpx,path_daw)\n",
    "    \n",
    "def plot(g,label='x'):\n",
    "#     type(g) = pd.DataFrame\n",
    "    plt.subplots(figsize=(10, 6))\n",
    "    plt.fill_between(g.index,y1 = g['ma'] - g['std'],y2=g['ma']+g['std'],alpha=0.3)\n",
    "    plt.plot(g.index,g['ma'])\n",
    "    plt.xlabel(label)\n",
    "    plt.ylabel('reward')\n",
    "    plt.grid(True)\n",
    "    \n",
    "def make_plot_data(reward_log, ma=5):\n",
    "#     type(reward_log)==list\n",
    "\n",
    "    length = len(reward_log)\n",
    "    reward_log = np.array(reward_log)\n",
    "    reward_dict = {}\n",
    "    if ma%2==0:\n",
    "        print(\"ma must be odd number.\")\n",
    "        return \n",
    "    \n",
    "    \n",
    "    sride = ma//2\n",
    "    try:\n",
    "        for i in range(sride,length-sride):\n",
    "            reward_dict[i] = {'reward':reward_log[i],'ma':reward_log[i-sride:i+sride+1].mean(),\n",
    "                             'std':reward_log[i-sride:i+sride+1].std()}\n",
    "    except:\n",
    "        print(\"Error.\")\n",
    "    \n",
    "    return pd.DataFrame(reward_dict).T\n",
    "     \n",
    "def easy_plot(df,xlabel='episode',ylabel='reward'):\n",
    "    plt.subplots(figsize=(10, 6))\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.grid(True)\n",
    "    plt.plot(df)\n",
    "    plt.show()\n",
    "    \n",
    "def make_df_con(path_tpx,path_daw):\n",
    "    df_tpx = DataFramePreProcessing(path_tpx).load_df()\n",
    "    df_daw = DataFramePreProcessing(path_daw,is_daw=True).load_df()\n",
    "    daw_p = df_daw.pct_change()\n",
    "    df_con = pd.concat([daw_p,df_tpx],axis = 1,join='inner').astype(float)\n",
    "    df_tmp = df_con.drop(df_con[ df_con['volume']==0].index)\n",
    "    return df_tmp\n",
    "\n",
    "def grid_search(x_train,y_train,x_test,y_test):\n",
    "    trains = xgb.DMatrix(x_train.astype(float), label=y_train)\n",
    "    tests = xgb.DMatrix(x_test.astype(float), label=y_test)\n",
    "\n",
    "    base_params = {\n",
    "        'booster': 'gbtree',\n",
    "        'objective':'binary:logistic',\n",
    "        'eval_metric': 'rmse',\n",
    "        'random_state':100,\n",
    "        'use_label_encoder':False\n",
    "    }\n",
    "\n",
    "    watchlist = [(trains, 'train'), (tests, 'eval')]\n",
    "    tmp_params = copy.deepcopy(base_params)\n",
    "    \n",
    "#     インナー関数\n",
    "    def optimizer(trial):\n",
    "        eta = trial.suggest_uniform('eta', 0.01, 0.3)\n",
    "        max_depth = trial.suggest_int('max_depth', 3, 15)\n",
    "        __lambda = trial.suggest_uniform('lambda', 0.7, 2)\n",
    "        n_estimators = trial.suggest_int('n_estimators', 3, 20)\n",
    "        learning_rate = trial.suggest_uniform('lambda', 0.01, 1)\n",
    "        reg_alpha = trial.suggest_uniform('reg_alpha', 0.01, 1)\n",
    "        reg_lambda = trial.suggest_uniform('reg_lambda', 0.01, 1)\n",
    "        importance_type = trial.suggest_categorical('importance_type',\n",
    "                                                    ['gain', 'weight', 'cover','total_gain','total_cover'])\n",
    "\n",
    "        tmp_params['eta'] = eta\n",
    "        tmp_params['max_depth'] = max_depth\n",
    "        tmp_params['lambda'] = __lambda\n",
    "        tmp_params['n_estimators'] = n_estimators\n",
    "        tmp_params['learning_rate'] = learning_rate\n",
    "        tmp_params['reg_alpha'] = reg_alpha\n",
    "        tmp_params['reg_lambda'] = reg_lambda\n",
    "        tmp_params['importance_type'] = importance_type\n",
    "        model = xgb.train(tmp_params, trains, num_boost_round=50)\n",
    "        predicts = model.predict(tests)\n",
    "        r2 = r2_score(y_test, predicts)\n",
    "        print(f'#{trial.number}, Result: {r2}, {trial.params}')\n",
    "        return r2\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(optimizer, n_trials=500)\n",
    "    print(study.best_params)\n",
    "    print(study.best_value)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / 1 + np.exp(-x)  \n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "\n",
    "def return_latest_data_path(folder_name):\n",
    "    path_ = '/Users/rince/Desktop/StockPriceData/%s/*.csv' % folder_name\n",
    "    file = glob.glob(path_)\n",
    "    path_tpx = sorted(file)[-1]\n",
    "    path_ = '/Users/rince/Desktop/StockPriceData/DAW/*.csv'\n",
    "    file = glob.glob(path_)\n",
    "    path_daw = sorted(file)[-1]\n",
    "    return path_tpx, path_daw\n",
    "\n",
    "def load_csv(load_path):\n",
    "    df = pd.read_csv(load_path, index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a05fa4-2a84-4a69-97f5-30e4bd779b84",
   "metadata": {
    "tags": []
   },
   "source": [
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de4afc4e-8a22-46aa-babb-4575d6a08317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Experience = namedtuple(\"Experience\", [\"s\",\"a\",\"r\",\"n_s\",\"n_a\",\"d\"])\n",
    "\n",
    "class DataFramePreProcessing():\n",
    "\n",
    "    \n",
    "    def __init__(self, path_, is_daw=False):\n",
    "        self.path_ = path_\n",
    "        self.is_daw = is_daw\n",
    "\n",
    "        \n",
    "    def load_df(self):\n",
    "        if self.is_daw:\n",
    "            d='d'\n",
    "        else:\n",
    "            d=''\n",
    "        FILE = glob.glob(self.path_)\n",
    "        df = pd.read_csv(FILE[0])\n",
    "        df = df.rename(columns={df.columns[0]:'nan',df.columns[1]:'nan',df.columns[2]:'nan',\\\n",
    "                                    df.columns[3]:'day',df.columns[4]:'nan',df.columns[5]:d+'open',\\\n",
    "                                    df.columns[6]:d+'high',df.columns[7]:d+'low',df.columns[8]:d+'close',\\\n",
    "                                       df.columns[9]:d+'volume',})\n",
    "        df = df.drop('nan',axis=1)\n",
    "        df = df.drop(df.index[0])\n",
    "        df['day'] = pd.to_datetime(df['day'],format='%Y/%m/%d')\n",
    "        df.set_index('day',inplace=True)\n",
    "\n",
    "        return df.astype(float)\n",
    "    \n",
    "class PlotTrade():\n",
    "    \n",
    "    \n",
    "    def __init__(self, df_chart,label=''):\n",
    "        self.df_chart = df_chart\n",
    "        plt.clf()\n",
    "        self.fig, self.ax = plt.subplots(figsize=(10, 6))\n",
    "        self.ax.plot(self.df_chart,label=label)\n",
    "        plt.legend()\n",
    "        \n",
    "    def add_span(self, start_time,end_time):\n",
    "        self.ax.axvspan(start_time, end_time, color=\"gray\", alpha=0.3)\n",
    "        \n",
    "    \n",
    "    def add_plot(self, df_plot,label=''):\n",
    "        self.ax.plot(df_plot,label=label)\n",
    "        plt.legend()\n",
    "        \n",
    "        \n",
    "    def show(self):\n",
    "        self.ax.grid()\n",
    "        labels = self.ax.get_xticklabels()\n",
    "        plt.setp(labels, rotation=15, fontsize=12)\n",
    "        plt.show()\n",
    "         \n",
    "class ValidatePlot(PlotTrade):\n",
    "    \n",
    "    \n",
    "    def __init__(self, df_chart, is_validate=False):\n",
    "        pass\n",
    "        \n",
    "    def add_span(self, start_time,end_time):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def add_plot(self, df_plot):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def show(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class TechnicalSimulation():\n",
    "    \n",
    "    \n",
    "    def __init__(self,ma_short=5, ma_long=25, hold_day=5, year=2021):\n",
    "        self.ma_short = ma_short\n",
    "        self.ma_long = ma_long\n",
    "        self.hold_day = hold_day\n",
    "        self.year = year\n",
    "        \n",
    "        \n",
    "    def process(self,df):\n",
    "        df_process = df.copy()\n",
    "        df_process['ma_short'] = df_process['close'].rolling(self.ma_short).mean()\n",
    "        df_process['ma_long']  = df_process['close'].rolling(self.ma_long).mean()\n",
    "        return df_process[df_process.index.year==self.year]\n",
    "    \n",
    "    \n",
    "    def is_buyable(self, short_line, long_line, index_):\n",
    "#         1=<index<=len-1 仮定\n",
    "        long_is_upper = long_line.iloc[index_-1]>=short_line.iloc[index_-1]\n",
    "        long_is_lower = long_line.iloc[index_+1]<=short_line.iloc[index_+1]\n",
    "        buyable = long_is_upper and long_is_lower\n",
    "        return buyable\n",
    "    \n",
    "    \n",
    "    def is_sellable(self, short_line, long_line, index_):\n",
    "        long_is_lower = long_line.iloc[index_-1]<=short_line.iloc[index_-1]\n",
    "        long_is_upper = long_line.iloc[index_+1]>=short_line.iloc[index_+1]\n",
    "        sellable = long_is_upper and long_is_lower\n",
    "        return sellable\n",
    "        \n",
    "        \n",
    "    def simulate(self,df,is_validate=False):\n",
    "        df_process = self.process(df)\n",
    "        is_bought = False\n",
    "        hold_count_day = 0\n",
    "        index_buy = 0\n",
    "        index_sell = 0\n",
    "        pl = PlotTrade(df_process['close'],label='close')\n",
    "        pl.add_plot(df_process['ma_short'],label='ma_5')\n",
    "        pl.add_plot(df_process['ma_long'],label='ma_25')   \n",
    "        prf = 0\n",
    "        start_time = 0\n",
    "        end_time = 0\n",
    "        short_line = df_process['ma_short']\n",
    "        long_line  = df_process['ma_long']\n",
    "        trade_count = 0\n",
    "        for_plot1=[]\n",
    "        for_plot2=[]\n",
    "        self.pr_log = pd.DataFrame()\n",
    "        self.pr_log.index = df.index\n",
    "        self.pr_log['reward'] = [0.0] * len(self.pr_log)\n",
    "        self.pr_log['eval_reward'] = self.pr_log['reward'].tolist()\n",
    "        eval_price = 0\n",
    "        total_eval_price = 0\n",
    "        \n",
    "        \n",
    "        for i in range(5,len(df_process)-1):\n",
    "            \n",
    "            \n",
    "            total_eval_price = prf\n",
    "            self.pr_log['reward'].loc[df_process.index[i]] = prf \n",
    "            self.pr_log['eval_reward'].loc[df_process.index[i]] = total_eval_price\n",
    "            if not is_bought:\n",
    "                \n",
    "                if self.is_buyable(short_line,long_line,i):\n",
    "                    index_buy = df_process['close'].iloc[i]\n",
    "                    is_bought = True\n",
    "                    start_time = df_process.index[i]\n",
    "                    hold_count_day = 0\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            \n",
    "            else:\n",
    "                \n",
    "                if self.is_sellable(short_line,long_line,i) or hold_count_day==self.hold_day:\n",
    "                    index_cell = df_process['close'].iloc[i]\n",
    "                    end_time = df_process.index[i]\n",
    "                    prf += index_cell - index_buy\n",
    "                    total_eval_price = prf\n",
    "                    self.pr_log['reward'].loc[df_process.index[i]] = prf \n",
    "                    self.pr_log['eval_reward'].loc[df_process.index[i]] = total_eval_price\n",
    "                    trade_count+=1\n",
    "                    is_bought = False\n",
    "                    hold_count_day = 0\n",
    "                    pl.add_span(start_time,end_time)\n",
    "                else:\n",
    "                    hold_count_day+=1\n",
    "                    eval_price = df_process['close'].iloc[i] - index_buy\n",
    "                    total_eval_price += eval_price\n",
    "                    self.pr_log['eval_reward'].loc[df_process.index[i]] = total_eval_price\n",
    "                    \n",
    "        \n",
    "        if is_bought and hold_count_day>0:\n",
    "            end_time = df_process['close'].index[-1]\n",
    "            pl.add_span(start_time,end_time)\n",
    "            eval_price = df_process['close'].iloc[-1] - index_buy\n",
    "            total_eval_price += eval_price\n",
    "            self.pr_log['eval_reward'].loc[df_process.index[-1]] = total_eval_price\n",
    "        \n",
    "    \n",
    "        if not is_validate:        \n",
    "            print(\"Total profit {}.\".format(prf))\n",
    "            print(\"Trade count\",trade_count)\n",
    "            pl.show()    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def return_profit_rate(self, path_tpx,wallet=2500):\n",
    "        df_tpx = DataFramePreProcessing(path_tpx).load_df()\n",
    "        self.simulate(df_tpx,is_validate=True)\n",
    "        self.pr_log['reward'] = self.pr_log['reward'].map(lambda x: x/wallet)\n",
    "        self.pr_log['eval_reward'] = self.pr_log['eval_reward'].map(lambda x: x/wallet)\n",
    "        return self.pr_log\n",
    "\n",
    "class Action(Enum):\n",
    "    BUY  = -1\n",
    "    STAY = 0\n",
    "    SELL = 1\n",
    "    \n",
    "class Environment():\n",
    "    \n",
    "    \n",
    "    def __init__(self, x_train, price_chart):\n",
    "        self.x_train = x_train # state list\n",
    "        self.is_holding = False\n",
    "        self.time = 0 # x_trainのindex\n",
    "        self.price_chart = price_chart\n",
    "        self.bought_price = 0\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.time=0\n",
    "        self.is_holding = False\n",
    "        self.bought_price = 0\n",
    "        return self.x_train.iloc[self.time].tolist()\n",
    "        \n",
    "    \n",
    "    def actions(self):\n",
    "        return [Action.BUY, Action.STAY, Action.SELL]\n",
    "    \n",
    "    \n",
    "#* ERROR!!!\n",
    "    def state(self):\n",
    "        try:\n",
    "            return self.x_train.iloc[self.time].tolist()\n",
    "        except:\n",
    "            print(\"Error index :\",self.time)\n",
    "            print(\"length      :\",len(self.x_train))\n",
    "            print(\"x_train:\",self.x_train)\n",
    "    \n",
    "    \n",
    "    def reward_func(self, action):\n",
    "        reward=0\n",
    "#* for solving the state(self)'s error, self.time -3 . \n",
    "        if self.time >= len(self.price_chart)-2: #売り切らずにエピソードを終えた時は評価額を報酬とする\n",
    "            \n",
    "            \n",
    "            if self.is_holding:\n",
    "                reward = self.price_chart.iloc[self.time+1] - self.bought_price\n",
    "            else:\n",
    "                reward = 0\n",
    "                \n",
    "            return reward, True\n",
    "        \n",
    "        \n",
    "        else:     \n",
    "            \n",
    "            \n",
    "            if action==Action.BUY:\n",
    "                reward=0\n",
    "                if not self.is_holding:\n",
    "                    self.is_holding = True\n",
    "                    self.bought_price = self.price_chart.iloc[self.time+1]\n",
    "            \n",
    "            elif action==Action.STAY:\n",
    "                reward=0\n",
    "            \n",
    "            elif action==Action.SELL:\n",
    "                reward = 0\n",
    "                if self.is_holding:\n",
    "                    reward = self.price_chart.iloc[self.time+1] - self.bought_price\n",
    "                    self.bought_price = 0\n",
    "                    self.is_holding=False\n",
    "            \n",
    "            return reward, False\n",
    "            \n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        reward, done = self.reward_func(action)\n",
    "        self.time += 1\n",
    "        next_state = self.state()\n",
    "        return next_state, reward, done\n",
    "    \n",
    "class SigmoidEnv(Environment):\n",
    "\n",
    "    \n",
    "    def sigmoid(self, x_):\n",
    "        return 1/(1+np.exp(-x_))\n",
    "    \n",
    "     \n",
    "    def reward_func(self, action):\n",
    "        reward=0\n",
    "        \n",
    "        if self.time >= len(self.price_chart)-2: #売り切らずにエピソードを終えた時は評価額を報酬とする\n",
    "            \n",
    "            \n",
    "            if self.is_holding:\n",
    "                reward = self.price_chart.iloc[self.time+1] - self.bought_price\n",
    "            else:\n",
    "                reward = 0\n",
    "                \n",
    "            return 2*self.sigmoid(reward)-1, True\n",
    "        \n",
    "        \n",
    "        else:     \n",
    "            \n",
    "            \n",
    "            if action==Action.BUY:\n",
    "                reward=0\n",
    "                if not self.is_holding:\n",
    "                    self.is_holding = True\n",
    "                    self.bought_price = self.price_chart.iloc[self.time+1]\n",
    "            \n",
    "            elif action==Action.STAY:\n",
    "                reward=0\n",
    "            \n",
    "            elif action==Action.SELL:\n",
    "                reward = 0\n",
    "                if self.is_holding:\n",
    "                    reward = self.price_chart.iloc[self.time+1] - self.bought_price\n",
    "                    self.bought_price = 0\n",
    "                    self.is_holding=False\n",
    "            \n",
    "            return 2*self.sigmoid(reward)-1, False\n",
    "        \n",
    "class TanhEnv(Environment):\n",
    "\n",
    " \n",
    "    def reward_func(self, action):\n",
    "        reward=0\n",
    "        \n",
    "        if self.time >= len(self.price_chart)-2: #売り切らずにエピソードを終えた時は評価額を報酬とする\n",
    "            \n",
    "            \n",
    "            if self.is_holding:\n",
    "                reward = self.price_chart.iloc[self.time+1] - self.bought_price\n",
    "            else:\n",
    "                reward = 0\n",
    "                \n",
    "            return np.tanh(reward), True\n",
    "        \n",
    "        \n",
    "        else:     \n",
    "            \n",
    "            \n",
    "            if action==Action.BUY:\n",
    "                reward=0\n",
    "                if not self.is_holding:\n",
    "                    self.is_holding = True\n",
    "                    self.bought_price = self.price_chart.iloc[self.time+1]\n",
    "            \n",
    "            elif action==Action.STAY:\n",
    "                reward=0\n",
    "            \n",
    "            elif action==Action.SELL:\n",
    "                reward = 0\n",
    "                if self.is_holding:\n",
    "                    reward = self.price_chart.iloc[self.time+1] - self.bought_price\n",
    "                    self.bought_price = 0\n",
    "                    self.is_holding=False\n",
    "            \n",
    "            return np.tanh(reward), False\n",
    "\n",
    "class FNAgent():\n",
    "    \n",
    "    \n",
    "    def __init__(self, epsilon, actions):\n",
    "        self.epsilon = epsilon\n",
    "        self.actions = actions\n",
    "        self.model = None\n",
    "        self.estimate_probs = False\n",
    "#         self.estimate_probs = True\n",
    "        self.initialized = False\n",
    "#         学習が終わったら, ε-greedy法をやめるためのフラグ変数\n",
    "        self.is_test = False\n",
    "        self.is_sarsa = False\n",
    "        \n",
    "        \n",
    "    def save(self, model_path):\n",
    "        self.model.save(model_path, overwrite=True, include_optimizer=False)\n",
    "        \n",
    "        \n",
    "    def policy(self, s):# 買ってたら戦略が変わる\n",
    "\n",
    "        if (np.random.random() < self.epsilon or not self.initialized) and not self.is_test:\n",
    "            return np.random.randint(len(self.actions))\n",
    "        else:\n",
    "            estimates = self.estimate(s)\n",
    "            if self.estimate_probs:\n",
    "                return np.random.choice(self.actions,size=1, p=softmax(estimates))[0]\n",
    "            else:\n",
    "                return np.argmax(estimates)\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, env, model_path, epsilon=0.0001):\n",
    "        actions = list(range(len(Action)))\n",
    "        agent = cls(epsilon, actions)\n",
    "        agent.model = K.models.load_model(model_path)\n",
    "        agent.initialized = True\n",
    "        return agent\n",
    "    \n",
    "    \n",
    "    def initialize(self, experiences):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def estimate(self, s):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def update(self, experiences, gamma):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    def play(self, env, episode_count=1):\n",
    "        pass\n",
    "    \n",
    "class ValueFunctionAgent(FNAgent):\n",
    "\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        joblib.dump(self.model, model_path)\n",
    "\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, env, model_path, epsilon=0.0001):\n",
    "        actions = list(range(len(Action)))\n",
    "        agent = cls(epsilon, actions)\n",
    "        agent.model = joblib.load(model_path)\n",
    "        agent.initialized = True\n",
    "        agent.is_test = True\n",
    "        return agent\n",
    "\n",
    "    \n",
    "    def initialize(self, experiences):\n",
    "        scaler = StandardScaler() # 特徴料(列)ごとに標準化してる\n",
    "#*         estimator = MLPRegressor(hidden_layer_sizes=(10, 10), max_iter=1)\n",
    "        estimator = MLPRegressor(hidden_layer_sizes=(10, 10), max_iter=1, early_stopping=True)\n",
    "        estimator.best_loss_ = 10**5\n",
    "#*         self.model = Pipeline([(\"scaler\", scaler), (\"estimator\", estimator)])\n",
    "#*       自作関数で, state_　標準化済み\n",
    "        self.model = estimator\n",
    "        states = np.vstack([e.s for e in experiences])\n",
    "#*         self.model.named_steps[\"scaler\"].fit(states)\n",
    "\n",
    "        \n",
    "        if not self.is_sarsa:\n",
    "            self.update([experiences[0]], gamma=0)\n",
    "        else:\n",
    "            self.update_sarsa([experiences[0]], gamma=0)\n",
    "        self.initialized = True\n",
    "        print(\"Done initialization. From now, begin training!\")\n",
    "\n",
    "    \n",
    "    def estimate(self, s):\n",
    "        s = np.array(s).reshape(1,-1)\n",
    "        # standard scaler してないけどいいのか？\n",
    "        estimated = self.model.predict(s)[0]\n",
    "        return estimated\n",
    "\n",
    "    \n",
    "    def _predict(self, states):\n",
    "        if self.initialized:\n",
    "            predicteds = self.model.predict(states)\n",
    "        else:\n",
    "            size = len(self.actions) * len(states)\n",
    "            predicteds = np.random.uniform(size=size)\n",
    "            predicteds = predicteds.reshape((-1, len(self.actions)))\n",
    "        return predicteds\n",
    "\n",
    "    \n",
    "    def update(self, experiences, gamma):        \n",
    "        states = np.vstack([e.s for e in experiences])\n",
    "        n_states = np.vstack([e.n_s for e in experiences])\n",
    "\n",
    "        estimateds = self._predict(states)\n",
    "        future = self._predict(n_states)\n",
    "\n",
    "\n",
    "        for i, e in enumerate(experiences):\n",
    "            reward = e.r\n",
    "            if not e.d:\n",
    "                reward += gamma * np.max(future[i])\n",
    "            estimateds[i][e.a] = reward\n",
    "\n",
    "        estimateds = np.array(estimateds)\n",
    "        self.model.partial_fit(states, estimateds)\n",
    "#*         states = self.model.named_steps[\"scaler\"].transform(states)\n",
    "#*         self.model.named_steps[\"estimator\"].partial_fit(states, estimateds)\n",
    "    \n",
    "\n",
    "#         ******************* SARSA法\n",
    "    def update_sarsa(self,experiences, gamma):\n",
    "        states = np.vstack([e.s for e in experiences])\n",
    "        n_states = np.vstack([e.n_s for e in experiences])\n",
    "\n",
    "        estimateds = self._predict(states)\n",
    "        future = self._predict(n_states)\n",
    "\n",
    "        for i, e in enumerate(experiences):\n",
    "            reward = e.r\n",
    "            if not e.d:\n",
    "                reward += gamma * future[i][e.n_a]\n",
    "            estimateds[i][e.a] = reward\n",
    "\n",
    "        \n",
    "        estimateds = np.array(estimateds)\n",
    "        self.model.partial_fit(states, estimateds)\n",
    "#*         states = self.model.named_steps[\"scaler\"].transform(states)\n",
    "#*         self.model.named_steps[\"estimator\"].partial_fit(states, estimateds)\n",
    "\n",
    "        \n",
    "    def play(self, env, episode_count=1,is_validate=False):\n",
    "        actions = env.actions()\n",
    "#       学習が終わったら, ε-greedy法をやめる\n",
    "        self.pr_log = pd.DataFrame()\n",
    "        self.pr_log.index = env.price_chart.index\n",
    "        self.pr_log['reward'] = [0.0] * len(self.pr_log)\n",
    "        self.pr_log['eval_reward'] = self.pr_log['reward'].tolist()\n",
    "        eval_price = 0\n",
    "        total_eval_price = 0\n",
    "        if self.initialized:\n",
    "            self.is_test = True\n",
    "            \n",
    "            \n",
    "        for e in range(episode_count):\n",
    "\n",
    "            s = env.reset()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            reward_log = []\n",
    "            if not is_validate:\n",
    "                pl = PlotTrade(env.price_chart)\n",
    "            else:\n",
    "                pl = ValidatePlot(None,is_validate=is_validate)\n",
    "            trade_count = 0\n",
    "            is_bought = False\n",
    "            start_time = env.price_chart.index[0]\n",
    "            end_time = env.price_chart.index[0]\n",
    "                \n",
    "            \n",
    "            while not done:\n",
    "                a = self.policy(s)\n",
    "                action = actions[a]\n",
    "                n_state, reward, done = env.step(action)\n",
    "                total_reward += reward    \n",
    "#                 *******\n",
    "                total_eval_price = total_reward\n",
    "    \n",
    "                self.pr_log['reward'].iloc[env.time] = total_reward\n",
    "                self.pr_log['eval_reward'].iloc[env.time] = total_eval_price\n",
    "                s = n_state\n",
    "                reward_log.append(total_reward)\n",
    "                #============ render ============\n",
    "\n",
    "                \n",
    "                if not is_bought:\n",
    "                    if env.is_holding and action == Action.BUY:\n",
    "                        start_time = env.price_chart.index[env.time]\n",
    "                        is_bought = True\n",
    "#                         ******\n",
    "                        eval_price = env.price_chart.iloc[env.time] - env.bought_price\n",
    "                        total_eval_price += eval_price\n",
    "                        self.pr_log['eval_reward'].iloc[env.time] = total_eval_price\n",
    "                else:\n",
    "                    if not env.is_holding and action == Action.SELL:\n",
    "                        end_time = env.price_chart.index[env.time]\n",
    "                        is_bought = False\n",
    "                        pl.add_span(start_time,end_time)\n",
    "                        trade_count += 1\n",
    "                    elif env.is_holding:\n",
    "                        eval_price = env.price_chart.iloc[env.time] - env.bought_price\n",
    "                        total_eval_price += eval_price\n",
    "                        self.pr_log['eval_reward'].iloc[env.time] = total_eval_price\n",
    "                        \n",
    "                        \n",
    "            else:\n",
    "                self.reward_log = reward_log\n",
    "                self.pr_log['reward'].iloc[-1] = total_reward\n",
    "                self.pr_log['eval_reward'].iloc[-1] = total_eval_price\n",
    "                if is_bought and env.is_holding:\n",
    "                    end_time = env.price_chart.index[-1]\n",
    "#                     **これが悪さしている気がしてならない\n",
    "                    eval_price = env.price_chart.iloc[-1] - env.price_chart.iloc[-2]\n",
    "                    self.pr_log['eval_reward'].iloc[-1] = self.pr_log['eval_reward'].iloc[-2] + eval_price\n",
    "                    pl.add_span(start_time,end_time)\n",
    "                    trade_count+=1\n",
    "                \n",
    "                    \n",
    "                if not is_validate:\n",
    "                    print(\"==================\")\n",
    "                    print(\"episode :\",e) \n",
    "                    print(\"Get reward {}.\".format(total_reward))\n",
    "                    print(\"Trade count {}.\".format(trade_count))\n",
    "                    print(\"Tomorrow action :\",action)\n",
    "                    pl.show()\n",
    "                return  total_reward, trade_count\n",
    "            \n",
    "    \n",
    "    def return_profit_rate(self,env_check,wallet=2500):\n",
    "        #         wallet      : 元本のこと 2500は25万円のこと\n",
    "        #         reward      : 実現収益\n",
    "        #         eval_reward : 評価損益も含んだ収益率 \n",
    "        self.play(env_check,is_validate=True)\n",
    "        self.pr_log['reward'] = self.pr_log['reward'].map(lambda x: x/wallet)\n",
    "        self.pr_log['eval_reward'] = self.pr_log['eval_reward'].map(lambda x: x/wallet)\n",
    "        return self.pr_log\n",
    "            \n",
    "        \n",
    "    def return_trade_log(self):\n",
    "        return self.reward_log\n",
    "    \n",
    "\n",
    "class TeacherAgent(ValueFunctionAgent):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def train(self,env):\n",
    "        self.experiences = []\n",
    "        actions = env.actions()\n",
    "        price_chart = self.price_chart.copy()\n",
    "        s = env.reset()\n",
    "        time_index = env.time\n",
    "        end = len(price_chart)\n",
    "        tmp_a = 0\n",
    "        bought_price = price_chart.iloc[time_index]\n",
    "#         a = 0 : buy, a = 1 : stay, a = 2 : sell\n",
    "        \n",
    "        while not done:\n",
    "\n",
    "            \n",
    "            for i in range(time_index,end):\n",
    "                bought_price = price_chart.iloc[time_index]\n",
    "                \n",
    "                if bought_price >  price_chart.iloc[i]:\n",
    "#                     損する取引で, 買ってたら, 買ってなかったことにする\n",
    "                    if tmp_a == 0:\n",
    "                elif bought_price < price_chart.iloc[i]:\n",
    "                    pass\n",
    "                else:\n",
    "                    pass\n",
    "                    \n",
    "                \n",
    "            a,reward,n_a = self.return_gods_sight(time_index, price_chart)\n",
    "            action = actions[a]\n",
    "            \n",
    "            n_state, reward, done = env.step(action)\n",
    "            \n",
    "            n_a = agent.policy(n_state)\n",
    "            \n",
    "# \n",
    "# s 　　　　　　　: 容易に取得できる\n",
    "# a 　　　　　　: time stpe 進めないと取得できない\n",
    "# reward 　　　: time stpe 進めないと取得できない\n",
    "# n_state : 容易に取得できる\n",
    "# n_a : time step 進めないと取得できない\n",
    "# done : 容易に取得できる\n",
    "            e = Experience(s, a, reward, n_state, n_a, done)\n",
    "            s = n_state\n",
    "            self.experiences.append(e)\n",
    "\n",
    "        \n",
    "class Trainer():\n",
    "\n",
    "    \n",
    "    def __init__(self, buffer_size=1024, batch_size=32,gamma=0.9, teacher_update_freq=3,patience=200):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.experiences = deque(maxlen=buffer_size)\n",
    "        self.training = False\n",
    "        self.training_count = 0\n",
    "        self.teacher_update_freq = teacher_update_freq\n",
    "        self.loss = 0\n",
    "        self.training_episode = 0\n",
    "#*         何回最高rewardを更新しなかったらstopさせるか\n",
    "        self.patience = patience\n",
    "        self.best_rewards = 0\n",
    "        self.best_model = None\n",
    "        self.check_point = 0\n",
    "        \n",
    "#* EarlyStopping 実装\n",
    "    def train_loop(self, env,agent, episode=200, initial_count=-1,env_sample=None,is_sarsa=False):\n",
    "        self.experiences = deque(maxlen=self.buffer_size)\n",
    "        self.training = False\n",
    "        self.training_count = 0\n",
    "        actions = env.actions()\n",
    "        reward_log = []\n",
    "        validate_reward_log = []\n",
    "        \n",
    "#*      best_rewardを更新したとき, best_modelも更新する\n",
    "        best_rewards = -10**7\n",
    "        best_model = None\n",
    "        check_point = 0 # type(episode)\n",
    "        update_count = 0\n",
    "        \n",
    "        \n",
    "        for i in range(episode):\n",
    "            s = env.reset()\n",
    "            done = False\n",
    "            step_count = 0\n",
    "            self.episode_begin(i, agent)\n",
    "            total_rewards = 0\n",
    "            \n",
    "            if i%100==0:\n",
    "                print(\"----------------------\")\n",
    "                print(\"episode :\",i)\n",
    "            \n",
    "            while not done:\n",
    "                \n",
    "\n",
    "                a = agent.policy(s)\n",
    "                action = actions[a]\n",
    "                n_state, reward, done = env.step(action)\n",
    "                n_a = agent.policy(n_state)\n",
    "                e = Experience(s, a, reward, n_state, n_a, done)\n",
    "                total_rewards += reward\n",
    "                self.experiences.append(e)\n",
    "                \n",
    "                \n",
    "                if not self.training and len(self.experiences) == self.buffer_size:\n",
    "                    if is_sarsa:\n",
    "                        agent.is_sarsa=True\n",
    "                    self.begin_train(i, agent)\n",
    "                    self.training = True\n",
    "\n",
    "                self.step(i, step_count, agent, e,is_sarsa)\n",
    "\n",
    "                s = n_state\n",
    "                step_count += 1\n",
    "            else:\n",
    "                self.episode_end(i, step_count, agent)\n",
    "                reward_log.append(total_rewards)\n",
    "#         検証用のlog\n",
    "                if env_sample!=None:\n",
    "                    validate_reward, dummy = agent.play(env_sample,is_validate=True)\n",
    "                    validate_reward_log.append(validate_reward)\n",
    "                if not self.training and initial_count > 0 and i >= initial_count:\n",
    "                    self.begin_train(i, agent)\n",
    "                    self.training = True\n",
    "\n",
    "\n",
    "                if self.training:\n",
    "                    self.training_count += 1\n",
    "                \n",
    "#*       best_reward, best_modelの更新                  \n",
    "                if best_rewards < total_rewards and i>=20:\n",
    "                    check_point = i\n",
    "                    best_rewards = total_rewards\n",
    "                    best_model = agent.model\n",
    "                    update_count += 1\n",
    "                    self.check_point = check_point\n",
    "                    self.best_rewards = best_rewards\n",
    "                    self.best_model = best_model\n",
    "##        early stopping 実装\n",
    "                if check_point + self.patience <= i:\n",
    "                    print(\"Done Early Stopping\")\n",
    "                    print(\"check_point episode :\",check_point)\n",
    "                    print(\"update_count        :\",update_count)\n",
    "                    print(\"best rewards        :\",best_rewards)\n",
    "                    agent.model = best_model\n",
    "                    break\n",
    "                \n",
    "\n",
    "        print(\"train reward\")         \n",
    "        plt.clf() \n",
    "        plt.plot(reward_log)\n",
    "        plt.xlabel('episode')\n",
    "        plt.ylabel('reward')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        if env_sample!=None:\n",
    "            print(\"validate data reward\")\n",
    "            plt.clf() \n",
    "            plt.plot(validate_reward_log)\n",
    "            plt.xlabel('episode')\n",
    "            plt.ylabel('reward')\n",
    "            plt.show()\n",
    "        \n",
    "        self.reward_log = reward_log\n",
    "        self.validate_reward_log = validate_reward_log\n",
    "        \n",
    "        \n",
    "    def return_reward_log(self):\n",
    "        return self.reward_log, self.validate_reward_log\n",
    "    \n",
    "    \n",
    "    def episode_begin(self, episode, agent):\n",
    "        self.loss = 0\n",
    "\n",
    "    \n",
    "    def begin_train(self, episode, agent):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def step(self, episode, step_count, agent, experience):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def episode_end(self, episode, step_count, agent):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def is_event(self, count, interval):\n",
    "        return True if count != 0 and count % interval == 0 else False\n",
    "\n",
    "    \n",
    "    def get_recent(self, count):\n",
    "        recent = range(len(self.experiences) - count, len(self.experiences))\n",
    "        return [self.experiences[i] for i in recent]\n",
    "    \n",
    "class ValueFunctionTrainer(Trainer):\n",
    "\n",
    "    \n",
    "    def train(self, env, episode_count=250, epsilon=0.01, initial_count=-1,env_sample=None,is_sarsa=False):\n",
    "        actions = list(range(len(Action)))\n",
    "        agent = ValueFunctionAgent(epsilon, actions)\n",
    "        self.training_episode = episode_count\n",
    "        self.train_loop(env, agent, episode_count, initial_count,env_sample,is_sarsa)\n",
    "        return agent\n",
    "\n",
    "   \n",
    "    def begin_train(self, episode, agent):\n",
    "        agent.initialize(self.experiences)\n",
    "\n",
    "    \n",
    "    def step(self, episode, step_count, agent, experience,is_sarsa):\n",
    "        if self.training:\n",
    "#*             ここでPrioritized Experience Replay 実装？\n",
    "            batch = random.sample(self.experiences, self.batch_size)\n",
    "            if not is_sarsa:\n",
    "                agent.update(batch, self.gamma)\n",
    "            else:\n",
    "                agent.update_sarsa(batch,self.gamma)\n",
    "      \n",
    "    \n",
    "    def episode_end(self, episode, step_count, agent):\n",
    "        pass\n",
    "            \n",
    "            # 減衰探索\n",
    "            # diff = (self.initial_epsilon - self.final_epsilon)\n",
    "            # decay = diff / self.training_episode\n",
    "            # agent.epsilon = max(agent.epsilon -decay, self.final_epsilon)\n",
    "\n",
    "class XGBSimulation():\n",
    "    \n",
    "    \n",
    "    def __init__(self, xgb_model, alpha=0.70):\n",
    "        self.xgb_model = xgb_model\n",
    "        self.alpha = alpha\n",
    "        self.acc_df = None\n",
    "        self.y_check = None\n",
    "        self.ma_long = 0\n",
    "        self.ma_short = 0\n",
    "        \n",
    "        \n",
    "    \n",
    "    def make_df_con(self, path_tpx,path_daw):\n",
    "        df_tpx = DataFramePreProcessing(path_tpx).load_df()\n",
    "        df_daw = DataFramePreProcessing(path_daw,is_daw=True).load_df()\n",
    "        daw_p = df_daw.pct_change()\n",
    "        df_con = pd.concat([daw_p,df_tpx],axis = 1,join='inner').astype(float)\n",
    "        df_tmp = df_con.drop(df_con[ df_con['volume']==0].index)\n",
    "        return df_tmp\n",
    "    \n",
    "    \n",
    "    def make_check_data(self,path_tpx,path_daw):\n",
    "        df_con = self.make_df_con(path_tpx,path_daw)\n",
    "        mk = MakeTrainData(df_con,test_rate=1.0)\n",
    "        x_check, y_check, x_dummy, y_dummy = mk.make_data()\n",
    "        self.ma_short = mk.ma_short\n",
    "        self.ma_long = mk.ma_long\n",
    "        return x_check, y_check\n",
    "    \n",
    "    \n",
    "    def eval_proba(self, x_test, y_test):\n",
    "        predict_proba = self.xgb_model.predict_proba(x_test.astype(float))\n",
    "        df = pd.DataFrame(columns = ['score','Up precision','Down precision','Up recall','Down recall','up_num','down_num'])\n",
    "        j=0\n",
    "        acc_dict = {'TU':0,'FU':0,'TD':0,'FD':0}\n",
    "        \n",
    "        \n",
    "        for i in range(len(predict_proba)):\n",
    "            row = predict_proba[i]\n",
    "            label = np.argmax(row)\n",
    "            proba = row[label]\n",
    "            if proba > self.alpha:\n",
    "                if y_test[i]==label:\n",
    "                    if label==0:\n",
    "                        acc_dict['TD'] += 1\n",
    "                    else:\n",
    "                        acc_dict['TU'] += 1\n",
    "                else:\n",
    "                    if label==0:\n",
    "                        acc_dict['FD'] += 1\n",
    "                    else:\n",
    "                        acc_dict['FU'] += 1\n",
    "\n",
    "\n",
    "        denom = 0\n",
    "        for idx, key in enumerate(acc_dict):\n",
    "            denom += acc_dict[key]\n",
    "        \n",
    "        try:\n",
    "            TU = acc_dict['TU']\n",
    "            FU = acc_dict['FU']\n",
    "            TD = acc_dict['TD']\n",
    "            FD = acc_dict['FD']\n",
    "            score = (TU + TD)/(denom)\n",
    "            prec_u = TU/(TU + FU)\n",
    "            prec_d = TD/(TD + FD)\n",
    "            recall_u = TU/(TU + FD)\n",
    "            recall_d = TD/(TD + FU)\n",
    "            up_num = TU+FD\n",
    "            down_num = TD+FU\n",
    "            down_num\n",
    "            col_list = [score,prec_u,prec_d,recall_u,recall_d,up_num,down_num]\n",
    "            df.loc[j] = col_list\n",
    "            j+=1\n",
    "            return df\n",
    "        except:\n",
    "            print(\"division by zero\")\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    def return_df_con(self,path_tpx,path_daw):\n",
    "        df_con =  self.make_df_con(path_tpx,path_daw)\n",
    "        return df_con\n",
    "    \n",
    "    \n",
    "    def return_grad(self, df, index, gamma=0, delta=0,):\n",
    "        grad_ma_short = df['ma_short'].iloc[index+1] - df['ma_short'].iloc[index]\n",
    "        grad_ma_long  = df['ma_long'].iloc[index+1] - df['ma_long'].iloc[index]\n",
    "        strategy = ''\n",
    "        \n",
    "        if grad_ma_long >= gamma:\n",
    "            strategy = 'normal'\n",
    "        elif grad_ma_long < delta:\n",
    "            strategy = 'reverse'\n",
    "        else:\n",
    "            print(\"No such threshold\")\n",
    "        return strategy\n",
    "        \n",
    "    \n",
    "    def return_split_df(self,df,start_year=2021,end_year=2021,start_month=1,end_month=12):\n",
    "        df = df[df.index.year>=start_year]\n",
    "        if start_year <= end_year:\n",
    "            df = df[df.index.year<=end_year]\n",
    "        if len(set(df.index.year))==1:\n",
    "            df = df[df.index.month>=start_month]\n",
    "            df = df[df.index.month<=end_month]\n",
    "        else:\n",
    "            df_tmp = df[df.index.year==start_year]\n",
    "            last_year_index = df_tmp[df_tmp.index.month==start_month].index[0]\n",
    "#             new_year_index = df[df.index.month==end_year].index[-1]\n",
    "            df = df.loc[last_year_index:]\n",
    "        return df\n",
    "    \n",
    "    \n",
    "#*    日付変更できるように変更\n",
    "    def simulate(self, path_tpx, path_daw, is_validate=False,strategy='normal',is_online=False,start_year=2021,end_year=2021,start_month=1,end_month=12,ma_short=5,ma_long=25,is_variable_strategy=False):\n",
    "        x_check, y_check = self.make_check_data(path_tpx,path_daw)\n",
    "        y_ = pd.DataFrame(y_check)\n",
    "        y_.index = x_check.index\n",
    "        x_check = self.return_split_df(x_check,start_year=start_year,end_year=end_year,start_month=start_month,end_month=end_month)\n",
    "        y_ = self.return_split_df(y_,start_year=start_year,end_year=end_year,start_month=start_month,end_month=end_month)\n",
    "        y_check = y_.values.reshape(-1).tolist()\n",
    "        length = len(x_check)\n",
    "        predict_proba = self.xgb_model.predict_proba(x_check.astype(float))\n",
    "        is_bought = False\n",
    "        index_buy = 0\n",
    "        index_sell = 0\n",
    "        prf = 0\n",
    "        trade_count = 0\n",
    "        df_con = self.return_df_con(path_tpx,path_daw)\n",
    "        df_con['ma_short'] = df_con['close'].rolling(self.ma_short).mean()\n",
    "        df_con['ma_long']  = df_con['close'].rolling(self.ma_long).mean()\n",
    "        df_con = df_con.iloc[self.ma_long:]\n",
    "        df_con = self.return_split_df(df_con,start_year=start_year,end_year=end_year,start_month=start_month,end_month=end_month)\n",
    "        pl = PlotTrade(df_con['close'],label='close')\n",
    "        pl.add_plot(df_con['ma_short'],label='ma_short')\n",
    "        pl.add_plot(df_con['ma_long'],label='ma_long')\n",
    "        prf_list = []\n",
    "        self.pr_log = pd.DataFrame()\n",
    "        self.pr_log.index = x_check.index\n",
    "        self.pr_log['reward'] = [0.0] * len(self.pr_log)\n",
    "        self.pr_log['eval_reward'] = self.pr_log['reward'].tolist()\n",
    "        eval_price = 0\n",
    "        total_eval_price = 0\n",
    "#*      オンライン学習用の学習データ   \n",
    "        x_tmp = x_check.copy()\n",
    "        y_tmp = y_.copy()\n",
    "        current_date = x_tmp.index[0]\n",
    "        acc_df = pd.DataFrame()\n",
    "        acc_df.index = x_tmp.index\n",
    "        acc_df['pred'] = [-1] * len(acc_df)\n",
    "#* 判定不能は -1, 騰貴予測は 1, 下落予測は 0\n",
    "        \n",
    "        \n",
    "        for i in range(length-1):\n",
    "            \n",
    "            \n",
    "            row = predict_proba[i]\n",
    "            label = np.argmax(row)\n",
    "            prob = row[label]\n",
    "            total_eval_price = prf\n",
    "            self.pr_log['reward'].loc[df_con.index[i]] = prf \n",
    "            self.pr_log['eval_reward'].loc[df_con.index[i]] = total_eval_price\n",
    "#             label==0 -> down\n",
    "#             label==1 -> up\n",
    "#*          オンライン学習\n",
    "            tmp_date = x_tmp.index[i]\n",
    "            if current_date.month!=tmp_date.month and is_online:\n",
    "#             x_ = x_tmp.loc[:x_tmp.index]\n",
    "                x_ = x_tmp[current_date<=x_tmp.index]\n",
    "                x_ = x_[x_.index<tmp_date]\n",
    "                y_ = y_tmp[current_date<=y_tmp.index]\n",
    "                y_ = y_[y_.index<tmp_date]\n",
    "#                 param_dist = {'objective':'binary:logistic', 'n_estimators':16,'use_label_encoder':False,\n",
    "#                  'max_depth':4}\n",
    "#                 tmp_xgb = xgb.XGBClassifier(**param_dist)\n",
    "                self.xgb_model = self.xgb_model.fit(x_,y_)\n",
    "                predict_proba = self.xgb_model.predict_proba(x_check.astype(float))\n",
    "                current_date = tmp_date\n",
    "            \n",
    "            if prob > self.alpha:\n",
    "                if label == 0:\n",
    "                    acc_df.iloc[i] = 0\n",
    "                else: #l able == 1 \n",
    "                    acc_df.iloc[i] = 1\n",
    "            \n",
    "            \n",
    "            if is_variable_strategy:\n",
    "                strategy = self.return_grad(df_con, index=i,gamma=0, delta=0)\n",
    "            \n",
    "                \n",
    "            if strategy=='reverse':\n",
    "            \n",
    "                if not is_bought:\n",
    "    #                 下がって買い\n",
    "                    if label==0 and prob>self.alpha:\n",
    "                        index_buy = df_con['close'].loc[x_check.index[i+1]]\n",
    "                        start_time = x_check.index[i+1]\n",
    "                        is_bought = True\n",
    "                else:\n",
    "    #                 上がって売り\n",
    "                    if label==1 and prob>self.alpha:\n",
    "                        index_sell = df_con['close'].loc[x_check.index[i+1]]\n",
    "                        end_time = x_check.index[i+1]\n",
    "                        prf += index_sell - index_buy\n",
    "                        prf_list.append(index_sell - index_buy)\n",
    "                        is_bought = False\n",
    "                        trade_count += 1\n",
    "                        pl.add_span(start_time,end_time)\n",
    "                    else:\n",
    "                        eval_price = df_con['close'].iloc[i] - index_buy\n",
    "                        total_eval_price += eval_price\n",
    "                        self.pr_log['eval_reward'].loc[df_con.index[i]] = total_eval_price\n",
    "                        \n",
    "                        \n",
    "            elif strategy=='normal':\n",
    "                \n",
    "                if not is_bought:\n",
    "    #                 上がって買い\n",
    "                    if label==1 and prob>self.alpha:\n",
    "                        index_buy = df_con['close'].loc[x_check.index[i+1]]\n",
    "                        start_time = x_check.index[i+1]\n",
    "                        is_bought = True\n",
    "                else:\n",
    "    #                 下がって売り\n",
    "                    if label==0 and prob>self.alpha:\n",
    "                        index_sell = df_con['close'].loc[x_check.index[i+1]]\n",
    "                        end_time = x_check.index[i+1]\n",
    "                        prf += index_sell - index_buy\n",
    "                        prf_list.append(index_sell - index_buy)\n",
    "                        is_bought = False\n",
    "                        trade_count += 1\n",
    "                        pl.add_span(start_time,end_time)\n",
    "                    else:\n",
    "                        eval_price = df_con['close'].iloc[i] - index_buy\n",
    "                        total_eval_price += eval_price\n",
    "                        self.pr_log['eval_reward'].loc[df_con.index[i]] = total_eval_price\n",
    "            else:\n",
    "                print(\"No such strategy.\")\n",
    "                return \n",
    "                  \n",
    "        \n",
    "        if is_bought:\n",
    "            index_sell = df_con['close'].loc[x_check.index[-1]] \n",
    "            prf += index_sell - index_buy\n",
    "            prf_list.append(index_sell - index_buy)\n",
    "            end_time = x_check.index[-1]\n",
    "            trade_count+=1\n",
    "            pl.add_span(start_time,end_time)\n",
    "\n",
    "        \n",
    "        self.pr_log['reward'].loc[df_con.index[-1]] = prf \n",
    "        self.pr_log['eval_reward'].loc[df_con.index[-1]] = total_eval_price\n",
    "        prf_array = np.array(prf_list)\n",
    "        self.acc_df = acc_df\n",
    "        self.y_check = y_check\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            if not is_validate:\n",
    "                print(\"Total profit :{}\".format(prf))\n",
    "                print(\"Trade count  :{}\".format(trade_count))\n",
    "                print(\"Max profit   :{}\".format(prf_array.max()))\n",
    "                print(\"Min profit   :{}\".format(prf_array.min()))\n",
    "                print(\"Mean profit  :{}\".format(prf_array.mean()))\n",
    "                if not is_online:\n",
    "                    df = self.eval_proba(x_check,y_check)\n",
    "                else:\n",
    "                    df = self.calc_acc(acc_df, y_check)\n",
    "                print(df)\n",
    "                print(\"\")\n",
    "                pl.show()\n",
    "        except:\n",
    "            print(\"no trade\")\n",
    "            \n",
    "    \n",
    "    def simulate_sm(self, path_tpx, path_daw, sm, is_validate=False,is_online=False,start_year=2021,end_year=2021,start_month=1,end_month=12,ma_short=5,ma_long=25,theta=0.0001):\n",
    "        x_check, y_check = self.make_check_data(path_tpx,path_daw)\n",
    "        y_ = pd.DataFrame(y_check)\n",
    "        y_.index = x_check.index\n",
    "        x_check = self.return_split_df(x_check,start_year=start_year,end_year=end_year,start_month=start_month,end_month=end_month)\n",
    "        y_ = self.return_split_df(y_,start_year=start_year,end_year=end_year,start_month=start_month,end_month=end_month)\n",
    "        y_check = y_.values.reshape(-1).tolist()\n",
    "        length = len(x_check)\n",
    "        predict_proba = self.xgb_model.predict_proba(x_check.astype(float))\n",
    "        is_bought = False\n",
    "        index_buy = 0\n",
    "        index_sell = 0\n",
    "        prf = 0\n",
    "        trade_count = 0\n",
    "        df_con = self.return_df_con(path_tpx,path_daw)\n",
    "        df_con['ma_short'] = df_con['close'].rolling(self.ma_short).mean()\n",
    "        df_con['ma_long']  = df_con['close'].rolling(self.ma_long).mean()\n",
    "        df_con = df_con.iloc[self.ma_long:-1]\n",
    "        df_con = self.return_split_df(df_con,start_year=start_year,end_year=end_year,start_month=start_month,end_month=end_month)\n",
    "        pl = PlotTrade(df_con['close'],label='close')\n",
    "        pl.add_plot(df_con['ma_short'],label='ma_short')\n",
    "        pl.add_plot(df_con['ma_long'],label='ma_long')\n",
    "        prf_list = []\n",
    "        self.pr_log = pd.DataFrame()\n",
    "        self.pr_log.index = x_check.index\n",
    "        self.pr_log['reward'] = [0.0] * len(self.pr_log)\n",
    "        self.pr_log['eval_reward'] = self.pr_log['reward'].tolist()\n",
    "        eval_price = 0\n",
    "        total_eval_price = 0\n",
    "#*      オンライン学習用の学習データ   \n",
    "        x_tmp = x_check.copy()\n",
    "        y_tmp = y_.copy()\n",
    "        current_date = x_tmp.index[0]\n",
    "        acc_df = pd.DataFrame()\n",
    "        acc_df.index = x_tmp.index\n",
    "        acc_df['pred'] = [-1] * len(acc_df)\n",
    "        x_sm, y_sm = sm.make_train_data(path_tpx, path_daw,year=start_year,theta=theta)\n",
    "        x_sm = self.return_split_df(x_sm,start_year=start_year,end_year=end_year,start_month=start_month,end_month=end_month)\n",
    "        buy_sign = sm.model.predict(x_sm)\n",
    "#* 判定不能は -1, 騰貴予測は 1, 下落予測は 0\n",
    "        \n",
    "        \n",
    "        for i in range(length-1):\n",
    "            \n",
    "            \n",
    "            row = predict_proba[i]\n",
    "            label = np.argmax(row)\n",
    "            prob = row[label]\n",
    "            total_eval_price = prf\n",
    "            \n",
    "            self.pr_log['reward'].loc[df_con.index[i]] = prf \n",
    "            self.pr_log['eval_reward'].loc[df_con.index[i]] = total_eval_price\n",
    "#             label==0 -> down\n",
    "#             label==1 -> up\n",
    "#*          オンライン学習\n",
    "            tmp_date = x_tmp.index[i]\n",
    "            if current_date.month!=tmp_date.month and is_online:\n",
    "#             x_ = x_tmp.loc[:x_tmp.index]\n",
    "                x_ = x_tmp[current_date<=x_tmp.index]\n",
    "                x_ = x_[x_.index<tmp_date]\n",
    "                y_ = y_tmp[current_date<=y_tmp.index]\n",
    "                y_ = y_[y_.index<tmp_date]\n",
    "#                 param_dist = {'objective':'binary:logistic', 'n_estimators':16,'use_label_encoder':False,\n",
    "#                  'max_depth':4}\n",
    "#                 tmp_xgb = xgb.XGBClassifier(**param_dist)\n",
    "                self.xgb_model = self.xgb_model.fit(x_,y_)\n",
    "                predict_proba = self.xgb_model.predict_proba(x_check.astype(float))\n",
    "                current_date = tmp_date\n",
    "            \n",
    "            if prob > self.alpha:\n",
    "                if label == 0:\n",
    "                    acc_df.iloc[i] = 0\n",
    "                else: #l able == 1 \n",
    "                    acc_df.iloc[i] = 1\n",
    "                    \n",
    "#                     「買い」 サインの時\n",
    "            if buy_sign[i]==1:\n",
    "                if prob >0.5 :\n",
    "                    strategy='normal'\n",
    "                else:\n",
    "                    strategy='reverse'\n",
    "            else:\n",
    "                strategy=None\n",
    "                \n",
    "\n",
    "            if strategy=='reverse' and buy_sign[i]==1:\n",
    "            \n",
    "                if not is_bought:\n",
    "    #                 下がって買い\n",
    "                    if label==0 and prob>self.alpha:\n",
    "                        index_buy = df_con['close'].loc[x_check.index[i+1]]\n",
    "                        start_time = x_check.index[i+1]\n",
    "                        is_bought = True\n",
    "                else:\n",
    "    #                 上がって売り\n",
    "                    if label==1 and prob>self.alpha:\n",
    "                        index_sell = df_con['close'].loc[x_check.index[i+1]]\n",
    "                        end_time = x_check.index[i+1]\n",
    "                        prf += index_sell - index_buy\n",
    "                        prf_list.append(index_sell - index_buy)\n",
    "                        is_bought = False\n",
    "                        trade_count += 1\n",
    "                        pl.add_span(start_time,end_time)\n",
    "                    else:\n",
    "                        eval_price = df_con['close'].iloc[i] - index_buy\n",
    "                        total_eval_price += eval_price\n",
    "                        self.pr_log['eval_reward'].loc[df_con.index[i]] = total_eval_price\n",
    "                        \n",
    "                        \n",
    "            elif strategy=='normal' and buy_sign[i]==1:\n",
    "                \n",
    "                if not is_bought:\n",
    "    #                 上がって買い\n",
    "                    if label==1 and prob>self.alpha:\n",
    "                        index_buy = df_con['close'].loc[x_check.index[i+1]]\n",
    "                        start_time = x_check.index[i+1]\n",
    "                        is_bought = True\n",
    "                else:\n",
    "    #                 下がって売り\n",
    "                    if label==0 and prob>self.alpha:\n",
    "                        index_sell = df_con['close'].loc[x_check.index[i+1]]\n",
    "                        end_time = x_check.index[i+1]\n",
    "                        prf += index_sell - index_buy\n",
    "                        prf_list.append(index_sell - index_buy)\n",
    "                        is_bought = False\n",
    "                        trade_count += 1\n",
    "                        pl.add_span(start_time,end_time)\n",
    "                    else:\n",
    "                        eval_price = df_con['close'].iloc[i] - index_buy\n",
    "                        total_eval_price += eval_price\n",
    "                        self.pr_log['eval_reward'].loc[df_con.index[i]] = total_eval_price\n",
    "            \n",
    "            \n",
    "            elif strategy==None:\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        \n",
    "        if is_bought:\n",
    "            index_sell = df_con['close'].loc[x_check.index[-1]] \n",
    "            prf += index_sell - index_buy\n",
    "            prf_list.append(index_sell - index_buy)\n",
    "            end_time = x_check.index[-1]\n",
    "            trade_count+=1\n",
    "            pl.add_span(start_time,end_time)\n",
    "\n",
    "        \n",
    "        self.pr_log['reward'].loc[df_con.index[-1]] = prf \n",
    "        self.pr_log['eval_reward'].loc[df_con.index[-1]] = total_eval_price\n",
    "        prf_array = np.array(prf_list)\n",
    "        self.acc_df = acc_df\n",
    "        self.y_check = y_check\n",
    "            \n",
    "        \n",
    "        try:\n",
    "            if not is_validate:\n",
    "                print(\"Total profit :{}\".format(prf))\n",
    "                print(\"Trade count  :{}\".format(trade_count))\n",
    "                print(\"Max profit   :{}\".format(prf_array.max()))\n",
    "                print(\"Min profit   :{}\".format(prf_array.min()))\n",
    "                print(\"Mean profit  :{}\".format(prf_array.mean()))\n",
    "                if not is_online:\n",
    "                    df = self.eval_proba(x_check,y_check)\n",
    "                else:\n",
    "                    df = self.calc_acc(acc_df, y_check)\n",
    "                print(df)\n",
    "                print(\"\")\n",
    "                pl.show()\n",
    "        except:\n",
    "            print(\"no trade\")\n",
    "            \n",
    "    \n",
    "    def calc_acc(self, acc_df, y_check):\n",
    "        df = pd.DataFrame(columns = ['score','Up precision','Down precision','Up recall','Down recall','up_num','down_num'])\n",
    "        acc_dict = {'TU':0,'FU':0,'TD':0,'FD':0}\n",
    "        \n",
    "        \n",
    "        for i in range(len(acc_df)):\n",
    "            \n",
    "            label = acc_df['pred'].iloc[i]\n",
    "            if y_check[i]==label:\n",
    "                if label==0:\n",
    "                    acc_dict['TD'] += 1\n",
    "                else:#label = 1 : UP\n",
    "                    acc_dict['TU'] += 1\n",
    "            else:\n",
    "                if label==0:\n",
    "                    acc_dict['FD'] += 1\n",
    "                else:\n",
    "                    acc_dict['FU'] += 1\n",
    "\n",
    "\n",
    "        denom = 0\n",
    "        for idx, key in enumerate(acc_dict):\n",
    "            denom += acc_dict[key]\n",
    "        \n",
    "        try:\n",
    "            TU = acc_dict['TU']\n",
    "            FU = acc_dict['FU']\n",
    "            TD = acc_dict['TD']\n",
    "            FD = acc_dict['FD']\n",
    "            score = (TU + TD)/(denom)\n",
    "            prec_u = TU/(TU + FU)\n",
    "            prec_d = TD/(TD + FD)\n",
    "            recall_u = TU/(TU + FD)\n",
    "            recall_d = TD/(TD + FU)\n",
    "            up_num = TU+FD\n",
    "            down_num = TD+FU\n",
    "            col_list = [score,prec_u,prec_d,recall_u,recall_d,up_num,down_num]\n",
    "            df.loc[0] = col_list\n",
    "            return df\n",
    "        except:\n",
    "            print(\"division by zero\")\n",
    "            return None\n",
    "        \n",
    "      \n",
    "    def return_accuracy(self, path_tpx,path_daw,strategy='normal',is_online=False,start_year=2021,start_month=1):\n",
    "        self.simulate(path_tpx,path_daw,is_validate=True,strategy=strategy,is_online=is_online)\n",
    "        y_check = pd.DataFrame(self.y_check)\n",
    "        y_check.index = self.acc_df.index\n",
    "        acc_df = self.acc_df.copy()\n",
    "        acc_df = acc_df[acc_df.index.year==start_year]\n",
    "        acc_df = acc_df[acc_df.index.month>=start_month]\n",
    "        y_check = y_check[y_check.index.year==start_year]\n",
    "        y_check = y_check[y_check.index.month>=start_month]\n",
    "        df = self.calc_acc(acc_df,y_check.values)\n",
    "        return df\n",
    "    \n",
    "        \n",
    "    def show_result(self, path_tpx,path_daw,strategy='normal'):\n",
    "        x_check, y_check = self.make_check_data(path_tpx,path_daw)  \n",
    "        self.simulate(x_check,y_check,strategy)\n",
    "        \n",
    "        \n",
    "    def return_profit_rate(self, path_tpx,path_daw,wallet=2500,strategy='normal',is_online=False,start_year=2021,start_month=1):\n",
    "        self.simulate(path_tpx,path_daw, is_validate=True,strategy=strategy,is_online=is_online,start_year=start_year,start_month=start_month)\n",
    "        self.pr_log['reward'] = self.pr_log['reward'].map(lambda x: x/wallet)\n",
    "        self.pr_log['eval_reward'] = self.pr_log['eval_reward'].map(lambda x: x/wallet)\n",
    "        return self.pr_log\n",
    "                \n",
    "class MakeTrainData():\n",
    "    \n",
    "    \n",
    "    def __init__(self, df_con, test_rate=0.9, questions_index = [], is_bit_search=False,is_category=True,ma_short=5,ma_long=25):\n",
    "        self.df_con = df_con\n",
    "        self.test_rate = test_rate\n",
    "        self.questions_index = questions_index\n",
    "        self.is_bit_search = is_bit_search\n",
    "        self.is_category = is_category\n",
    "        self.ma_short = ma_short\n",
    "        self.ma_long = ma_long\n",
    "        \n",
    "        \n",
    "    def labeling(self):\n",
    "        if self.is_category:\n",
    "            up=1\n",
    "            down=0\n",
    "        else:\n",
    "            up=[0,1]\n",
    "            down=[1,0]\n",
    "        \n",
    "        \n",
    "        return up,down\n",
    "    \n",
    "    \n",
    "    def append_onehotlist(self, one_hot_list, questions):\n",
    "        for i in range(len(questions)):\n",
    "            if questions[i]:\n",
    "                one_hot_list.append(1)\n",
    "            else:\n",
    "                one_hot_list.append(0)\n",
    "                \n",
    "                \n",
    "    def add_ma(self):\n",
    "        df_process = self.df_con.copy()\n",
    "        df_process['ma_short'] = df_process['close'].rolling(self.ma_short).mean()\n",
    "        df_process['ma_long']  = df_process['close'].rolling(self.ma_long).mean()\n",
    "        df_process['std_short'] = df_process['close'].rolling(self.ma_short).std()\n",
    "        df_process['std_long']  = df_process['close'].rolling(self.ma_long).std()\n",
    "        return df_process\n",
    "                \n",
    "    \n",
    "    def make_question_column(self):\n",
    "        column_questions = [\n",
    "                'dawp_5',\n",
    "                'dawp_4',\n",
    "                'dawp_3',\n",
    "                'dawp_2',\n",
    "                'dawp_1',\n",
    "                'dawp_0',\n",
    "                'nikkeip_5',\n",
    "                'nikkeip_4',\n",
    "                'nikkeip_3',\n",
    "                'nikkeip_2',\n",
    "                'nikkeip_1',\n",
    "                'nikkeip_0',\n",
    "                'diff_rate',\n",
    "                'nikkei_volumep',\n",
    "                'std_s_5 ',\n",
    "                'std_s_4',\n",
    "                'std_s_3 ',\n",
    "                'std_s_2 ',\n",
    "                'std_s_1',\n",
    "                'std_s_0 ',\n",
    "                'std_l_5 ', \n",
    "                'std_l_4 ', \n",
    "                'std_l_3 ', \n",
    "                'std_l_2 ', \n",
    "                'std_l_1 ',\n",
    "                'std_l_0 ', \n",
    "                'vec_s_5 ', \n",
    "                'vec_s_4 ',\n",
    "                'vec_s_3 ', \n",
    "                'vec_s_2 ',\n",
    "                'vec_s_1 ', \n",
    "                'vec_l_5 ', \n",
    "                'vec_l_4 ', \n",
    "                'vec_l_3 ', \n",
    "                'vec_l_2 ', \n",
    "                'vec_l_1 '\n",
    "            ]\n",
    "        return column_questions\n",
    "        \n",
    "        \n",
    "    def make_data(self,is_check=False):\n",
    "        selected_column = []\n",
    "        if self.is_bit_search:\n",
    "            for i in self.questions_index:\n",
    "                selected_column.append(self.column[i])\n",
    "            dfx = pd.DataFrame(columns = selected_column)\n",
    "        else:\n",
    "            dfx = pd.DataFrame(columns = self.make_question_column())\n",
    "        df_tpx_p = self.df_con['close'].pct_change()\n",
    "        df_ans = []\n",
    "        day_sride = 5 # 何日前まで見るか　\n",
    "                      # default = 5\n",
    "                        \n",
    "        up, down = self.labeling()\n",
    "        end_point = -1\n",
    "        \n",
    "        \n",
    "        if is_check:\n",
    "            end_point = len(self.df_con)\n",
    "        else:\n",
    "            end_point = len(self.df_con)-1\n",
    "            \n",
    "            \n",
    "        for i in range(self.ma_long+day_sride,end_point):\n",
    "            dawp_5 = self.df_con['dclose'].iloc[i-5]\n",
    "            dawp_4 = self.df_con['dclose'].iloc[i-4]\n",
    "            dawp_3 = self.df_con['dclose'].iloc[i-3]\n",
    "            dawp_2 = self.df_con['dclose'].iloc[i-2]\n",
    "            dawp_1 = self.df_con['dclose'].iloc[i-1]\n",
    "            dawp_0 = self.df_con['dclose'].iloc[i]\n",
    "            nikkeip_5 = df_tpx_p.iloc[i-5]\n",
    "            nikkeip_4 = df_tpx_p.iloc[i-4]\n",
    "            nikkeip_3 = df_tpx_p.iloc[i-3]\n",
    "            nikkeip_2 = df_tpx_p.iloc[i-2]\n",
    "            nikkeip_1 = df_tpx_p.iloc[i-1]\n",
    "            nikkeip_0 = df_tpx_p.iloc[i]\n",
    "#             *_0 は最も最近のデータ, つまり昨日のデータ\n",
    "            \n",
    "            diff_high_low = self.df_con['high'].iloc[i] -self.df_con['low'].iloc[i]\n",
    "            diff_rate = diff_high_low / self.df_con['close'].iloc[i]\n",
    "            nikkei_volumep = (self.df_con['volume'].iloc[i] - self.df_con['volume'].iloc[i-1])/self.df_con['volume'].iloc[i-1]\n",
    "            \n",
    "            df_ma = self.add_ma()\n",
    "            std_s_5 = df_ma['std_short'].iloc[i-5]\n",
    "            std_s_4 = df_ma['std_short'].iloc[i-4]\n",
    "            std_s_3 = df_ma['std_short'].iloc[i-3]\n",
    "            std_s_2 = df_ma['std_short'].iloc[i-2]\n",
    "            std_s_1 = df_ma['std_short'].iloc[i-1]\n",
    "            std_s_0 = df_ma['std_short'].iloc[i]\n",
    "            std_l_5 = df_ma['std_long'].iloc[i-5]\n",
    "            std_l_4 = df_ma['std_long'].iloc[i-4]\n",
    "            std_l_3 = df_ma['std_long'].iloc[i-3]\n",
    "            std_l_2 = df_ma['std_long'].iloc[i-2]\n",
    "            std_l_1 = df_ma['std_long'].iloc[i-1]\n",
    "            std_l_0 = df_ma['std_long'].iloc[i]\n",
    "            \n",
    "            vec_s_5 = (df_ma['ma_short'].iloc[i] - df_ma['ma_short'].iloc[i-5])/5\n",
    "            vec_s_4 = (df_ma['ma_short'].iloc[i] - df_ma['ma_short'].iloc[i-4])/4\n",
    "            vec_s_3 = (df_ma['ma_short'].iloc[i] - df_ma['ma_short'].iloc[i-3])/3\n",
    "            vec_s_2 = (df_ma['ma_short'].iloc[i] - df_ma['ma_short'].iloc[i-2])/2\n",
    "            vec_s_1 = (df_ma['ma_short'].iloc[i] - df_ma['ma_short'].iloc[i-1])/1\n",
    "            vec_l_5 = (df_ma['ma_long'].iloc[i] - df_ma['ma_long'].iloc[i-5])/5\n",
    "            vec_l_4 = (df_ma['ma_long'].iloc[i] - df_ma['ma_long'].iloc[i-4])/4\n",
    "            vec_l_3 = (df_ma['ma_long'].iloc[i] - df_ma['ma_long'].iloc[i-3])/3\n",
    "            vec_l_2 = (df_ma['ma_long'].iloc[i] - df_ma['ma_long'].iloc[i-2])/2\n",
    "            vec_l_1 = (df_ma['ma_long'].iloc[i] - df_ma['ma_long'].iloc[i-1])/1\n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "    # ---------------Question----------------\n",
    "            questions = [\n",
    "                dawp_5,\n",
    "                dawp_4,\n",
    "                dawp_3,\n",
    "                dawp_2,\n",
    "                dawp_1,\n",
    "                dawp_0,\n",
    "                nikkeip_5,\n",
    "                nikkeip_4,\n",
    "                nikkeip_3,\n",
    "                nikkeip_2,\n",
    "                nikkeip_1,\n",
    "                nikkeip_0,\n",
    "                diff_rate,\n",
    "                nikkei_volumep,\n",
    "                std_s_5 ,\n",
    "                std_s_4,\n",
    "                std_s_3 ,\n",
    "                std_s_2 ,\n",
    "                std_s_1,\n",
    "                std_s_0 ,\n",
    "                std_l_5 , \n",
    "                std_l_4 , \n",
    "                std_l_3 , \n",
    "                std_l_2 , \n",
    "                std_l_1 ,\n",
    "                std_l_0 , \n",
    "                vec_s_5 , \n",
    "                vec_s_4 ,\n",
    "                vec_s_3 , \n",
    "                vec_s_2 ,\n",
    "                vec_s_1 , \n",
    "                vec_l_5 , \n",
    "                vec_l_4 , \n",
    "                vec_l_3 , \n",
    "                vec_l_2 , \n",
    "                vec_l_1 \n",
    "            ]\n",
    "        \n",
    "            \n",
    "            if self.is_bit_search:\n",
    "                selected_questions = []\n",
    "                for j in self.questions_index:\n",
    "                    selected_questions.append(questions[j])\n",
    "                    \n",
    "            else:\n",
    "                selected_questions = questions\n",
    "\n",
    "\n",
    "            dfx.loc[self.df_con.index[i]] = selected_questions\n",
    "            if not is_check:\n",
    "                tommorow_close = self.df_con['close'].iloc[i+1]\n",
    "                today_close    = self.df_con['close'].iloc[i]\n",
    "                if tommorow_close>today_close:\n",
    "                    df_ans.append(up)\n",
    "                else:\n",
    "                    df_ans.append(down)\n",
    "        \n",
    "        x_check = dfx\n",
    "        x_train = dfx.iloc[:int(len(dfx)*self.test_rate)]\n",
    "        x_test  = dfx.iloc[int(len(dfx)*self.test_rate):]\n",
    "        if not is_check:\n",
    "            y_train = df_ans[:int(len(dfx)*self.test_rate)]\n",
    "            y_test  = df_ans[int(len(dfx)*self.test_rate):]\n",
    "        \n",
    "        if not is_check:\n",
    "            return x_train, y_train, x_test, y_test\n",
    "        else:\n",
    "            chart_ = self.df_con.loc[x_check.index]\n",
    "            return x_check,chart_\n",
    "    \n",
    "    \n",
    "#     def make_check_data(self):\n",
    "        selected_column = []\n",
    "        dfx = pd.DataFrame(columns = self.make_question_column())\n",
    "        df_tpx_p = self.df_con['close'].pct_change()\n",
    "        df_ans = []\n",
    "        day_sride = 5 # 何日前まで見るか　\n",
    "                      # default = 5\n",
    "                        \n",
    "        up, down = self.labeling()\n",
    "        for i in range(self.ma_long,len(self.df_con)):\n",
    "            dawp_5 = self.df_con['dclose'].iloc[i-4]\n",
    "            dawp_4 = self.df_con['dclose'].iloc[i-3]\n",
    "            dawp_3 = self.df_con['dclose'].iloc[i-2]\n",
    "            dawp_2 = self.df_con['dclose'].iloc[i-1]\n",
    "            dawp_1 = self.df_con['dclose'].iloc[i]\n",
    "            nikkeip_5 = df_tpx_p.iloc[i-4]\n",
    "            nikkeip_4 = df_tpx_p.iloc[i-3]\n",
    "            nikkeip_3 = df_tpx_p.iloc[i-2]\n",
    "            nikkeip_2 = df_tpx_p.iloc[i-1]\n",
    "            nikkeip_1 = df_tpx_p.iloc[i]\n",
    "            \n",
    "            diff_high_low = self.df_con['high'].iloc[i] - \\\n",
    "                            self.df_con['low'].iloc[i]\n",
    "            diff_rate = diff_high_low / self.df_con['close'].iloc[i]\n",
    "            nikkei_volumep = (self.df_con['volume'].iloc[i] - self.df_con['volume'].iloc[i-1])\\\n",
    "            /self.df_con['volume'].iloc[i-1]\n",
    "            df_ma = self.add_ma()\n",
    "            ma_short = df_ma['ma_short'].iloc[i]\n",
    "            ma_long  = df_ma['ma_long'].iloc[i]\n",
    "    # ---------------Question----------------\n",
    "            questions = [\n",
    "                dawp_5,\n",
    "                dawp_4,\n",
    "                dawp_3,\n",
    "                dawp_2,\n",
    "                dawp_1,\n",
    "                nikkeip_5,\n",
    "                nikkeip_4,\n",
    "                nikkeip_3,\n",
    "                nikkeip_2,\n",
    "                nikkeip_1,\n",
    "                diff_rate,\n",
    "                nikkei_volumep,\n",
    "                ma_short,\n",
    "                ma_long\n",
    "            ]\n",
    "            selected_questions = questions\n",
    "            dfx.loc[self.df_con.index[i]] = selected_questions\n",
    "\n",
    "                \n",
    "        x_check = dfx\n",
    "        chart_ = self.df_con.loc[x_check.index]\n",
    "#         x_check, chart_のインデックス合わなくなるから注意\n",
    "        \n",
    "        return x_check, chart_\n",
    "    \n",
    "\n",
    "class LearnXGB():\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = xgb.XGBClassifier()\n",
    "        self.x_test = None\n",
    "    \n",
    "    \n",
    "    def learn_xgb(self, path_tpx, path_daw, test_rate=0.8, param_dist='None'):\n",
    "        x_train,y_train,x_test,y_test = self.make_xgb_data(path_tpx,path_daw,test_rate)\n",
    "        \n",
    "        if param_dist=='None':\n",
    "#             Grid search で求めたパラメタ 2021/11/21\n",
    "            param_dist = { 'n_estimators':16,'use_label_encoder':False,\n",
    "                 'max_depth':4}\n",
    "#             'objective':'binary:logistic',\n",
    "#      Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "        xgb_model = xgb.XGBClassifier(**param_dist)\n",
    "        hr_pred = xgb_model.fit(x_train.astype(float), np.array(y_train), eval_metric='logloss').predict(x_test.astype(float))\n",
    "        print(\"---------------------\")\n",
    "        y_proba_train = xgb_model.predict_proba(x_train)[:,1]\n",
    "        y_proba = xgb_model.predict_proba(x_test)[:,1]\n",
    "        print('AUC train:',roc_auc_score(y_train,y_proba_train))    \n",
    "        print('AUC test :',roc_auc_score(y_test,y_proba))\n",
    "        print(classification_report(np.array(y_test), hr_pred))\n",
    "        _, ax = plt.subplots(figsize=(12, 10))\n",
    "        xgb.plot_importance(xgb_model,ax=ax) \n",
    "        self.model = xgb_model\n",
    "        \n",
    "\n",
    "    def make_state(self,path_tpx,path_daw):\n",
    "        df_con = self.make_df_con(path_tpx,path_daw)\n",
    "        mk = MakeTrainData(df_con)\n",
    "        x_check, chart_ = mk.make_data(is_check=True)\n",
    "        state_ = self.model.predict_proba(x_check.astype(float))\n",
    "        chart_ = df_con['close'].loc[x_check.index[0]:x_check.index[-1]]\n",
    "        return state_, chart_\n",
    "        \n",
    "        \n",
    "    def make_xgb_data(self, path_tpx, path_daw, test_rate):\n",
    "        df_con = self.make_df_con(path_tpx,path_daw)\n",
    "        x_train, y_train, x_test, y_test = MakeTrainData(df_con,test_rate=test_rate).make_data()\n",
    "        return x_train,y_train,x_test,y_test\n",
    "    \n",
    "    \n",
    "    def make_df_con(self,path_tpx,path_daw):\n",
    "        df_tpx = DataFramePreProcessing(path_tpx).load_df()\n",
    "        df_daw = DataFramePreProcessing(path_daw,is_daw=True).load_df()\n",
    "        daw_p = df_daw.pct_change()\n",
    "        df_con = pd.concat([daw_p,df_tpx],axis = 1,join='inner').astype(float)\n",
    "        df_con = df_con.drop(df_con[ df_con['volume']==0].index)\n",
    "        return df_con\n",
    "    \n",
    "    \n",
    "    def make_check_data(self, path_tpx, path_daw):\n",
    "        df_con = self.make_df_con(path_tpx,path_daw)\n",
    "\n",
    "        mk = MakeTrainData(df_con)\n",
    "        x_check, chart_ = mk.make_data(is_check=True)\n",
    "        state_ = self.model.predict_proba(x_check.astype(float))\n",
    "\n",
    "        chart_ = mk.df_con['close'].loc[x_check.index[0]:x_check.index[-1]]\n",
    "        state_ = pd.DataFrame(state_)\n",
    "        state_['day'] = chart_.index\n",
    "        \n",
    "        state_.reset_index(inplace=True)\n",
    "        state_.set_index('day',inplace=True)\n",
    "        state_.drop('index',axis=1,inplace=True)\n",
    "        return state_, chart_\n",
    "    \n",
    "    \n",
    "    def predict_tomorrow(self, path_tpx, path_daw, alpha=0.5, day_length=50, is_online=False, start_year=2021,start_month=1,end_month=12):\n",
    "        sl = XGBSimulation(self.model,alpha=alpha)\n",
    "        sl.simulate(path_tpx,path_daw,start_year=start_year,start_month=start_month,end_month=end_month)\n",
    "        df_con = self.make_df_con(path_tpx,path_daw)\n",
    "        mk = MakeTrainData(df_con)\n",
    "        x_check, chart_ = mk.make_data(is_check=True)\n",
    "        tomorrow_predict = self.model.predict_proba(x_check)\n",
    "        print(\"df_con in predict_tomorrow\",df_con.index[-1])\n",
    "        print(\"today :\",x_check.index[-1])\n",
    "        print(\"tomorrow UP possibility\", tomorrow_predict[-1,1])\n",
    "    \n",
    "class LearnQN():\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.lx = LearnXGB()\n",
    "#         ***\n",
    "        self.trainer = None\n",
    "        self.QL_agent = None\n",
    "        self.state = None\n",
    "        self.env_type = None\n",
    "        self.ma_long = 0\n",
    "        self.ma_short = 0\n",
    "        \n",
    "        \n",
    "    def save(self, save_path):\n",
    "        date_ = datetime.datetime.now().strftime('%Y%m%d')\n",
    "        state=''\n",
    "        \n",
    "        \n",
    "        if type(self.state)==list:\n",
    "            for i in self.state:\n",
    "                state += (i+'_')\n",
    "        else:\n",
    "            state = self.state\n",
    "        \n",
    "        \n",
    "        name = 'xqn'+'_'+state+'_'+self.env_type+'_'+date_\n",
    "        with open(save_path+name+'.pickle', 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, save_path_qagent):\n",
    "        with open(save_path_qagent, 'rb') as f:\n",
    "             lq_copy = pickle.load(f)\n",
    "        cls(lq_copy.path_tpx,lq_copy.path_daw)\n",
    "        return lq_copy\n",
    "        \n",
    "        \n",
    "    def show_chart(self,chart_='None'):\n",
    "        if chart_=='None':\n",
    "            pl = PlotTrade(self.chart_)\n",
    "        else:\n",
    "            pl = PlotTrade(chart_)\n",
    "        pl.show()\n",
    "        \n",
    "    \n",
    "    def learn_xqn(self,path_tpx,path_daw,state='proba',env_type='profit',episode_count=100,train_year=2020,test_year=2021,is_sarsa=False):\n",
    "        state_ ,chart_ = self.make_df_state(self.lx,path_tpx,path_daw) \n",
    "        state_, chart_ = self.make_state(path_tpx,path_daw,state_,chart_,state)\n",
    "        \n",
    "        s_train = state_[state_.index.year==train_year]\n",
    "        s_test = state_[state_.index.year==test_year]\n",
    "        price_train = chart_[chart_.index.year==train_year]\n",
    "        price_test  = chart_[chart_.index.year==test_year]\n",
    "        self.env_type = env_type\n",
    "        \n",
    "        if env_type=='profit':\n",
    "            env_train = Environment(s_train,price_train)\n",
    "        elif env_type=='sigmoid':\n",
    "            env_train = SigmoidEnv(s_train,price_train)\n",
    "        elif env_type=='tanh':\n",
    "            env_train = TanhEnv(s_train,price_train)\n",
    "        else:\n",
    "            print(\"No such env_type.\")\n",
    "            return \n",
    "        \n",
    "        \n",
    "        env_test = Environment(s_test,price_test)\n",
    "        trainer = ValueFunctionTrainer()\n",
    "        trained = trainer.train(env_train,episode_count=episode_count,env_sample=env_test,is_sarsa=is_sarsa)   \n",
    "        trained.play(env_test)\n",
    "        self.QL_agent = trained\n",
    "        self.trainer = trainer\n",
    "        #         reward_log\n",
    "        self.train_reward_log, self.test_reward_log = trainer.return_reward_log()\n",
    "        self.test_trade_log  = trained.return_trade_log()\n",
    "        \n",
    "        \n",
    "    def return_reward_log(self):\n",
    "        return self.train_reward_log, self.test_reward_log\n",
    "    \n",
    "    \n",
    "    def return_test_trade_log(self):\n",
    "        return self.test_trade_log\n",
    "    \n",
    "    \n",
    "    def make_df_state(self, lx,path_tpx,path_daw):\n",
    "        lx.learn_xgb(path_tpx,path_daw)\n",
    "        state_,chart_ = lx.make_state(path_tpx,path_daw)\n",
    "        \n",
    "        df_state = pd.DataFrame(state_)\n",
    "        df_state['day'] = chart_.index\n",
    "        df_state.reset_index(inplace=True)\n",
    "        df_state.set_index('day',inplace=True)\n",
    "        df_state.drop('index',axis=1,inplace=True)\n",
    "        return df_state, chart_\n",
    "    \n",
    "    \n",
    "    def concat_df(self,path_tpx,path_daw):\n",
    "        df_tpx  = DataFramePreProcessing(path_tpx).load_df()\n",
    "        df_daw = DataFramePreProcessing(path_daw, is_daw=True).load_df()\n",
    "        daw_p = df_daw['dclose'].pct_change()\n",
    "        tpx_p = df_tpx['close'].pct_change()\n",
    "        df_con = pd.concat([daw_p,tpx_p],axis = 1,join='inner').astype(float)\n",
    "        df_con = df_con.rename(columns={'close': 'pclose'})\n",
    "        df_con = pd.concat([df_con,df_tpx['close']],axis = 1,join='inner').astype(float)\n",
    "        return df_con\n",
    "\n",
    "    \n",
    "#* 属性ごとに, 標準化     \n",
    "    def make_standard(self,state_,axis='tate'):\n",
    "#         axis = 1 が横\n",
    "        if axis=='yoko':\n",
    "            lambda_ = lambda x:(x-x.mean())/x.std()    \n",
    "            state_yoko = state_.apply(lambda_,axis=1)\n",
    "            return state_yoko\n",
    "        elif axis=='tate':\n",
    "            lambda_ = lambda x:(x-x.mean())/x.std()    \n",
    "            state_tate = state_.apply(lambda_,axis=0)\n",
    "            return state_tate\n",
    "        else:\n",
    "            print(\"No such axis\")\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def add_state(self,state,state_,df_con):\n",
    "        \n",
    "        \n",
    "        if state=='proba':\n",
    "            state_ = self.make_standard(state_,axis='tate')\n",
    "            # state_ = self.make_standard(state_,axis='yoko')\n",
    "            return state_ \n",
    "        \n",
    "        \n",
    "        elif state=='change_rate':\n",
    "            \n",
    "            df_pct = df_con.loc[:,['dclose','pclose']].iloc[1:]\n",
    "            state_ = pd.concat([df_pct,state_],axis = 1,join='inner').astype(float)\n",
    "            state_ = self.make_standard(state_,axis='tate')\n",
    "            # state_ = self.make_standard(state_,axis='yoko')\n",
    "            return state_\n",
    "        \n",
    "        \n",
    "        elif state=='moving_average':\n",
    "            \n",
    "            state_['ma_short'] = df_con['close'].rolling(self.ma_short).mean()\n",
    "            state_['ma_long']  = df_con['close'].rolling(self.ma_long).mean()\n",
    "            state_ = state_.iloc[self.ma_long:]\n",
    "            state_ = self.make_standard(state_,axis='tate')\n",
    "            # state_ = self.make_standard(state_,axis='yoko')\n",
    "            return state_\n",
    "        \n",
    "        \n",
    "        elif state=='std':\n",
    "            \n",
    "            state_['std_short'] = df_con['close'].rolling(self.ma_short).std()\n",
    "            state_['std_long']  = df_con['close'].rolling(self.ma_long).std()\n",
    "            state_ = state_.iloc[self.ma_long:]\n",
    "            state_ = self.make_standard(state_,axis='tate')\n",
    "            # state_ = self.make_standard(state_,axis='yoko')\n",
    "            return state_\n",
    "        \n",
    "        \n",
    "        elif state=='all':\n",
    "            \n",
    "            df_con['ma_short'] = df_con['close'].rolling(self.ma_short).mean()\n",
    "            df_con['ma_long']  = df_con['close'].rolling(self.ma_long).mean()\n",
    "            df_con['std_short'] = df_con['close'].rolling(self.ma_short).std()\n",
    "            df_con['std_long']  = df_con['close'].rolling(self.ma_long).std()\n",
    "            df_con = df_con.loc[:,['dclose','pclose','ma_short','ma_long','std_short','std_long']].iloc[self.ma_long:]\n",
    "            state_ = pd.concat([df_con,state_],axis = 1,join='inner').astype(float)\n",
    "            state_ = self.make_standard(state_,axis='tate')\n",
    "            # state_ = self.make_standard(state_,axis='yoko')\n",
    "            return state_\n",
    "       \n",
    "        \n",
    "        else:\n",
    "            print(\"No such state type.\")\n",
    "            return None\n",
    "    \n",
    "    \n",
    "    def make_state(self,path_tpx,path_daw,state_,chart_,states=['proba'], ma_short=5,ma_long=25):\n",
    "#         if type(state)==list:\n",
    "        self.ma_long = ma_long\n",
    "        self.ma_short = ma_short\n",
    "        self.state = states\n",
    "        df_con = self.concat_df(path_tpx,path_daw)\n",
    "        \n",
    "        \n",
    "        for state in states:\n",
    "            state_ = self.add_state(state,state_,df_con)\n",
    "        \n",
    "        \n",
    "        return state_, chart_.loc[state_.index]\n",
    "\n",
    "        \n",
    "    def predict_tomorrow(self,path_tpx,path_daw):\n",
    "        check_state, check_chart = self.lx.make_check_data(path_tpx,path_daw)\n",
    "        state = self.state\n",
    "        state_, chart_ = self.make_state(path_tpx,path_daw,check_state,check_chart,state=state)\n",
    "        s_check = state_.iloc[-50:]\n",
    "        price_check = chart_.iloc[-50:]\n",
    "        print(\"today :\", s_check.index[-1])\n",
    "        \n",
    "        env_check = Environment(s_check,price_check)\n",
    "        self.QL_agent.play(env_check)\n",
    "\n",
    "        \n",
    "    def return_profit_rate(self, path_tpx,path_daw,wallet=2500):\n",
    "        check_state, check_chart = self.lx.make_check_data(path_tpx,path_daw)\n",
    "#         OK\n",
    "        state = self.state\n",
    "        state_, chart_ = self.make_state(path_tpx,path_daw,check_state,check_chart,states=state)\n",
    "        s_check = state_\n",
    "        price_check = chart_\n",
    "        env_check = Environment(s_check,price_check)\n",
    "        pr_log =  self.QL_agent.return_profit_rate(env_check,wallet)\n",
    "        return pr_log\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35cc97f-aba9-419a-bdff-2ed360ab377d",
   "metadata": {},
   "source": [
    "# state 下落の確率もいれてね？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a227715-4c05-4e03-97ac-11150f445a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con = lq.concat_df(path_tpx,path_daw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37dd6a0-01e3-4317-84c0-1239d02c3e1c",
   "metadata": {},
   "source": [
    "# 標準化　行で標準化した例\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc89d9d6-261e-4732-a81d-cccb1006ff3e",
   "metadata": {},
   "source": [
    "見た限りこのデータじゃちゃんと学習\n",
    "しなさそう \\\n",
    "\n",
    "たて標準化　して　よこ標準化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5584a7a3-1cd3-4ef5-a643-3d9fa7ee8ac8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# メモ\n",
    "あとは横の標準化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0bd0bd-dda4-4dfc-9efd-79ec26c7ef69",
   "metadata": {},
   "source": [
    "# SARSA法\n",
    " \\\n",
    "$$\n",
    "gain = reward + \\gamma \\cdot self.Q[n\\_state][n\\_action]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5515e083-8e7f-4e3b-a153-0831d5161153",
   "metadata": {},
   "source": [
    "# FNAgent class でself.estimate_probがある\n",
    "行動価値でなく, 行動確率を学ばせたい場合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97852cff-2386-41f2-9392-cc270f208333",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb5ee8-36ae-4d27-82fe-3968e19905bd",
   "metadata": {},
   "source": [
    "kerasのニューラルネットにしてからなぜかバグる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd58a0f-dd4f-4219-991c-6fa46e5f431d",
   "metadata": {},
   "source": [
    "2011/11/23 21:00 追記, ちゃんと動いた\\\n",
    "バグは batch_size=1024, epochs=1 とすることで解消\\\n",
    "early_stoppingもちゃんと動いた\\\n",
    "\n",
    "\n",
    "sklearn model.get_paramsあり"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c08c1-e81c-40fe-ab1d-3355769995ae",
   "metadata": {},
   "source": [
    "# アイデア\n",
    "順張り, 逆張り　を選んで行動させればいいのでは?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc59cb79-6653-4141-bf4e-a118bbb4ad87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1 episode 19s in mac\n",
    "\n",
    "# lq.show_chart()\n",
    "lq_dict = {}\n",
    "episode_count=1000\n",
    "\n",
    "state0=['proba']\n",
    "state1=['std','change_rate','moving_average']\n",
    "state2=['std','change_rate']\n",
    "state3=['change_rate','moving_average']\n",
    "state4=['std','moving_average']\n",
    "state5=['std']\n",
    "state6=['moving_average']\n",
    "state7=['change_rate']\n",
    "\n",
    "\n",
    "env_types = ['profit','sigmoid','tanh']\n",
    "\n",
    "\n",
    "\n",
    "# time : 3129.7162601947784\n",
    "for state in [state7]:\n",
    "    name=''\n",
    "    for s in state:\n",
    "        name+=(s+'_')\n",
    "    for env_type in env_types:\n",
    "        for is_sarsa in [True,False]:\n",
    "            for i in range(10):\n",
    "                start_time = time.time()\n",
    "                lq = LearnQN()\n",
    "                print(\"state    :\",name)\n",
    "                print(\"env type :\",env_type)\n",
    "                lq.learn_xqn(path_tpx,path_daw,state=state,env_type=env_type,episode_count=episode_count,train_year=2020,test_year=2021,is_sarsa=is_sarsa)\n",
    "                lq_dict[name+env_type+'_'+str(is_sarsa)+'_'+str(i)] = lq\n",
    "                end_time = time.time()\n",
    "                print(\"time :\",end_time -start_time)\n",
    "                print(\"*********************************\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d92660-38d5-4c5f-ba03-a1b4e0ecfa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/Users/Owner/Desktop/'\n",
    "with open(save_path+'lq_dict.pickle', 'rb') as f:\n",
    "    lq_dict_copy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bcdb325-4ebb-429b-ac0f-9b8c7d9368e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/Users/Owner/Desktop/'\n",
    "with open(save_path+'lq_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(lq_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdd83a5-6463-4cae-b092-e5db76e61406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lq_dict_copy = lq_dict\n",
    "\n",
    "mean_train_reward_dict = {}\n",
    "mean_test_reward_dict = {}\n",
    "mean_pr_dict = {}\n",
    "tmp_name = ''\n",
    "error_list = []\n",
    "for i,key in enumerate(lq_dict_copy):\n",
    "    name = key[:-1]\n",
    "    tmp_train_df = pd.DataFrame([0 for i in range(1000)])\n",
    "    tmp_test_df = pd.DataFrame([0 for i in range(1000)])\n",
    "    tmp_pr_df = pd.DataFrame()\n",
    "    \n",
    "    if name == tmp_name:\n",
    "        continue\n",
    "    print(\"\\n\\n\\n\")\n",
    "    print(\"tmp_name\",tmp_name)\n",
    "    for i in range(10):\n",
    "        \n",
    "        # try:\n",
    "        tmp_name = name\n",
    "        lq_tmp = lq_dict_copy[tmp_name+str(i)]\n",
    "        train_reward, test_reward = lq_tmp.return_reward_log()\n",
    "        pr = lq_tmp.return_profit_rate(path_tpx_sim,path_daw_sim)\n",
    "        pr = pr[pr.index.year==2021]\n",
    "\n",
    "        tmp_pr_df[str(i)] = pr['eval_reward']\n",
    "\n",
    "\n",
    "        df_train = pd.DataFrame(train_reward)\n",
    "        df_train.rename(columns = {0:'reward'},inplace=True)\n",
    "        tmp_train_df = pd.merge(tmp_train_df,df_train,left_index=True,right_index=True,how='left')\n",
    "        tmp_train_df = tmp_train_df.fillna(0)\n",
    "\n",
    "\n",
    "        df_test = pd.DataFrame(test_reward)#\n",
    "        df_test.rename(columns = {0:'reward'},inplace=True)\n",
    "        tmp_test_df = pd.merge(tmp_test_df,df_test,left_index=True,right_index=True,how='left')\n",
    "        tmp_test_df = tmp_test_df.fillna(0)\n",
    "        # except:\n",
    "        #     error_list.append(tmp_name) \n",
    "        \n",
    "    \n",
    "    pr_ma = tmp_pr_df.mean(axis=1)\n",
    "    pr_std = tmp_pr_df.std(axis=1)\n",
    "    tmp_pr_df['ma'] = pr_ma\n",
    "    tmp_pr_df['std'] = pr_std\n",
    "\n",
    "    train_ma = tmp_train_df.mean(axis=1)\n",
    "    train_std = tmp_train_df.std(axis=1)\n",
    "    tmp_train_df['ma'] = train_ma\n",
    "    tmp_train_df['std'] = train_std\n",
    "\n",
    "    test_ma = tmp_test_df.mean(axis=1)\n",
    "    test_std = tmp_test_df.std(axis=1)\n",
    "    tmp_test_df['ma'] = test_ma\n",
    "    tmp_test_df['std'] = test_std\n",
    "    \n",
    "    mean_pr_dict[tmp_name] = tmp_pr_df[['ma','std']]\n",
    "    mean_train_reward_dict[tmp_name] = tmp_train_df[['ma','std']]\n",
    "    mean_test_reward_dict[tmp_name] = tmp_test_df[['ma','std']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "564c5b2e-972d-4014-9c9f-c30cedc58403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### state0=['proba']\n",
    "state1=['std','change_rate','moving_average']\n",
    "state2=['std','change_rate']\n",
    "state3=['change_rate','moving_average']\n",
    "state4=['std','moving_average']\n",
    "state5=['std']\n",
    "state6=['moving_average']\n",
    "state7=['change_rate']\n",
    "\n",
    "\n",
    "env_types = ['profit','sigmoid','tanh']\n",
    "# mean_train_reward_dict = {}\n",
    "# mean_test_reward_dict = {}\n",
    "# mean_pr_dict = {}\n",
    "'std_change_rate_moving_average_profit_True'\n",
    "# # time : 3129.7162601947784\n",
    "# for state in [state0,state1,state2,state3,state4,state5,state6,state7]:\n",
    "#     name=''\n",
    "#     for s in state:\n",
    "#         name+=(s+'_')\n",
    "#     for env_type in env_types:\n",
    "       \n",
    "error_key_list = []\n",
    "#         for is_sarsa in [True,False]:\n",
    "for i,key in enumerate(mean_train_reward_dict):\n",
    "# key = name+env_type+'_'+str(is_sarsa)\n",
    "    # print(\"\\n\\n\\n\")\n",
    "    try:\n",
    "        # print(key)\n",
    "        # print(\"\\n\\n\\n\")\n",
    "        # print(\"train\")\n",
    "        plot(mean_train_reward_dict[key],label=key)\n",
    "        # print(\"\\n\\n\\n\")\n",
    "        # print(\"test\")\n",
    "        plot(mean_test_reward_dict[key],label=key)\n",
    "        # print(\"\\n\\n\\n\")\n",
    "        # print(\"profit rate\")\n",
    "        delta = mean_pr_dict[key]['ma'].iloc[0]\n",
    "        mean_pr_dict[key]['ma'] = mean_pr_dict[key]['ma'].map(lambda x:x-delta)\n",
    "        plot(mean_pr_dict[key],label=key)\n",
    "    except:\n",
    "        error_key_list.append(key)\n",
    "        # print(\"error key\",key)\n",
    "\n",
    "\n",
    "               \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "                         \n",
    "    # print('key :',key)\n",
    "    # train_reward, test_reward = lq_dict_copy[key].return_reward_log()\n",
    "    # print(\"test_reward\")\n",
    "    # test_reward_dict = make_plot_data(test_reward,ma=19)\n",
    "    # plot(test_reward_dict)\n",
    "    # pr = lq_dict_copy[key].return_profit_rate(path_tpx,path_daw)\n",
    "    # pr = pr[pr.index.year==2021]\n",
    "    # easy_plot(pr['eval_reward'])\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49201b5f-ada2-41e9-a550-7a8259867ab2",
   "metadata": {},
   "source": [
    "# milestone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6ef91bd-5514-4557-8426-95388412960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path+'lq_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(lq_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e990c22b-5f29-4d6d-a61c-a6e88c07fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path+'lq_dict.pickle', 'rb') as f:\n",
    "    lq_dict_copy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2594f862-9f8b-4234-9447-bad7232bcff2",
   "metadata": {},
   "source": [
    "chengerate だけやってない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea0c083-7094-4ef8-8392-3642f802ec4e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'change_rate_moving_average_profit_True_0': <__main__.LearnQN at 0x21b0e4b0a30>,\n",
       " 'change_rate_moving_average_profit_True_1': <__main__.LearnQN at 0x21b150dbfa0>,\n",
       " 'change_rate_moving_average_profit_True_2': <__main__.LearnQN at 0x21b15b2d250>,\n",
       " 'change_rate_moving_average_profit_True_3': <__main__.LearnQN at 0x21b1636b4c0>,\n",
       " 'change_rate_moving_average_profit_True_4': <__main__.LearnQN at 0x21b173993d0>,\n",
       " 'change_rate_moving_average_profit_True_5': <__main__.LearnQN at 0x21b17be49d0>,\n",
       " 'change_rate_moving_average_profit_True_6': <__main__.LearnQN at 0x21b16793640>,\n",
       " 'change_rate_moving_average_profit_True_7': <__main__.LearnQN at 0x21b19520c10>,\n",
       " 'change_rate_moving_average_profit_True_8': <__main__.LearnQN at 0x21b1ad22220>,\n",
       " 'change_rate_moving_average_profit_True_9': <__main__.LearnQN at 0x21b1b54bcd0>,\n",
       " 'change_rate_moving_average_profit_False_0': <__main__.LearnQN at 0x21b1ca207f0>,\n",
       " 'change_rate_moving_average_profit_False_1': <__main__.LearnQN at 0x21b186e9fd0>,\n",
       " 'change_rate_moving_average_profit_False_2': <__main__.LearnQN at 0x21b18fd4790>,\n",
       " 'change_rate_moving_average_profit_False_3': <__main__.LearnQN at 0x21b1f4e42b0>,\n",
       " 'change_rate_moving_average_profit_False_4': <__main__.LearnQN at 0x21b1fd13880>,\n",
       " 'change_rate_moving_average_profit_False_5': <__main__.LearnQN at 0x21b2082baf0>,\n",
       " 'change_rate_moving_average_profit_False_6': <__main__.LearnQN at 0x21b210bad00>,\n",
       " 'change_rate_moving_average_profit_False_7': <__main__.LearnQN at 0x21b21a1a040>,\n",
       " 'change_rate_moving_average_profit_False_8': <__main__.LearnQN at 0x21b226f9460>,\n",
       " 'change_rate_moving_average_profit_False_9': <__main__.LearnQN at 0x21b23006070>,\n",
       " 'change_rate_moving_average_sigmoid_True_0': <__main__.LearnQN at 0x21b238489d0>,\n",
       " 'change_rate_moving_average_sigmoid_True_1': <__main__.LearnQN at 0x21b240b3340>,\n",
       " 'change_rate_moving_average_sigmoid_True_2': <__main__.LearnQN at 0x21b1d323700>,\n",
       " 'change_rate_moving_average_sigmoid_True_3': <__main__.LearnQN at 0x21b1dcccd00>,\n",
       " 'change_rate_moving_average_sigmoid_True_4': <__main__.LearnQN at 0x21b1e5246d0>,\n",
       " 'change_rate_moving_average_sigmoid_True_5': <__main__.LearnQN at 0x21b283df610>,\n",
       " 'change_rate_moving_average_sigmoid_True_6': <__main__.LearnQN at 0x21b28ccc640>,\n",
       " 'change_rate_moving_average_sigmoid_True_7': <__main__.LearnQN at 0x21b29526c70>,\n",
       " 'change_rate_moving_average_sigmoid_True_8': <__main__.LearnQN at 0x21b29eb6820>,\n",
       " 'change_rate_moving_average_sigmoid_True_9': <__main__.LearnQN at 0x21b2a773d60>,\n",
       " 'change_rate_moving_average_sigmoid_False_0': <__main__.LearnQN at 0x21b2b0815b0>,\n",
       " 'change_rate_moving_average_sigmoid_False_1': <__main__.LearnQN at 0x21b2ba2b790>,\n",
       " 'change_rate_moving_average_sigmoid_False_2': <__main__.LearnQN at 0x21b2c28c250>,\n",
       " 'change_rate_moving_average_sigmoid_False_3': <__main__.LearnQN at 0x21b2ccd7bb0>,\n",
       " 'change_rate_moving_average_sigmoid_False_4': <__main__.LearnQN at 0x21b2e60c0a0>,\n",
       " 'change_rate_moving_average_sigmoid_False_5': <__main__.LearnQN at 0x21b2ef199a0>,\n",
       " 'change_rate_moving_average_sigmoid_False_6': <__main__.LearnQN at 0x21b2f873be0>,\n",
       " 'change_rate_moving_average_sigmoid_False_7': <__main__.LearnQN at 0x21b3014bd90>,\n",
       " 'change_rate_moving_average_sigmoid_False_8': <__main__.LearnQN at 0x21b30b21d60>,\n",
       " 'change_rate_moving_average_sigmoid_False_9': <__main__.LearnQN at 0x21b3141ca00>,\n",
       " 'change_rate_moving_average_tanh_True_0': <__main__.LearnQN at 0x21b31cb1b20>,\n",
       " 'change_rate_moving_average_tanh_True_1': <__main__.LearnQN at 0x21b325e46a0>,\n",
       " 'change_rate_moving_average_tanh_True_2': <__main__.LearnQN at 0x21b32fe6fd0>,\n",
       " 'change_rate_moving_average_tanh_True_3': <__main__.LearnQN at 0x21b338e0880>,\n",
       " 'change_rate_moving_average_tanh_True_4': <__main__.LearnQN at 0x21b2465f940>,\n",
       " 'change_rate_moving_average_tanh_True_5': <__main__.LearnQN at 0x21b24eea910>,\n",
       " 'change_rate_moving_average_tanh_True_6': <__main__.LearnQN at 0x21b2588c490>,\n",
       " 'change_rate_moving_average_tanh_True_7': <__main__.LearnQN at 0x21b261aaa00>,\n",
       " 'change_rate_moving_average_tanh_True_8': <__main__.LearnQN at 0x21b26cdddf0>,\n",
       " 'change_rate_moving_average_tanh_True_9': <__main__.LearnQN at 0x21b2763b670>,\n",
       " 'change_rate_moving_average_tanh_False_0': <__main__.LearnQN at 0x21b2808faf0>,\n",
       " 'change_rate_moving_average_tanh_False_1': <__main__.LearnQN at 0x21b3c830820>,\n",
       " 'change_rate_moving_average_tanh_False_2': <__main__.LearnQN at 0x21b3d0a0c10>,\n",
       " 'change_rate_moving_average_tanh_False_3': <__main__.LearnQN at 0x21b3da6db50>,\n",
       " 'change_rate_moving_average_tanh_False_4': <__main__.LearnQN at 0x21b3e42a160>,\n",
       " 'change_rate_moving_average_tanh_False_5': <__main__.LearnQN at 0x21b3ec8eb20>,\n",
       " 'change_rate_moving_average_tanh_False_6': <__main__.LearnQN at 0x21b3f6922b0>,\n",
       " 'change_rate_moving_average_tanh_False_7': <__main__.LearnQN at 0x21b3ff133d0>,\n",
       " 'change_rate_moving_average_tanh_False_8': <__main__.LearnQN at 0x21b40939e20>,\n",
       " 'change_rate_moving_average_tanh_False_9': <__main__.LearnQN at 0x21b421aebe0>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lq_dict_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e07513d4-68ec-48b3-979b-bbbf9c99d252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lq_tmp = lq_dict['std_change_rate_profit_True_0']\n",
    "train_reward, test_reward = lq_tmp.return_reward_log()\n",
    "print(\"test_reward\")\n",
    "test_reward_dict = make_plot_data(test_reward,ma=19)\n",
    "plot(test_reward_dict)\n",
    "pr = lq_tmp.return_profit_rate(path_tpx_sim,path_daw_sim)\n",
    "pr = pr[pr.index.year==2021]\n",
    "easy_plot(pr['eval_reward'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "903e41ef-1942-4a59-a64d-270099d8b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_tpx_sim = '/Users/Owner/Desktop/StockPriceData/TOPIX/TOPIX_20211208.csv'\n",
    "# path_225 = '/Users/Owner/Desktop/StockPriceData/Stock_index/NK225_10years.csv'\n",
    "path_daw_sim = '/Users/Owner/Desktop/StockPriceData/DAW/DAW_20211208.csv'\n",
    "# path_bear = '/Users/Owner/Desktop/StockPriceData/Stock_index/R225BEAR_10years.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c090da0-ee22-4c62-b71e-a4876d9f53a0",
   "metadata": {},
   "source": [
    "# 累積収益率\n",
    "$$\n",
    "累積収益率 = \\frac{累積報酬}{元本}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c02ae8de-3ba1-4a4f-a372-55cc3c0e2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pr = lq.return_profit_rate(path_tpx_sim,path_daw_sim)\n",
    "pr = pr[pr.index.year==2021]\n",
    "# pr.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b46fc2-4689-4711-a7d3-9615a05ba12d",
   "metadata": {},
   "source": [
    "# Preict tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7098170f-fc24-422d-ac90-d076d33be9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today : 2021-11-18 00:00:00\n",
      "==================\n",
      "episode : 0\n",
      "Get reward -5.0.\n",
      "Trade count 6.\n",
      "Tomorrow action : Action.BUY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict_tomorrow(lq_dict['tanhFalse'],folder_name='TOPIX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e9eab1-bd00-4215-93dc-b9e6e0635f4a",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4b30a953-b8f1-4e1b-9b4e-3e1a2b42d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path =  '/Users/rince/Desktop/Sotsuron/code/model/RL/Qagent/hoge'\n",
    "lq.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545680eb-468d-46d2-b3ad-fc942b3437bc",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6e323ff2-f947-4133-a8ff-f100dcd048c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "AUC train: 0.860577203982112\n",
      "AUC test : 0.6767285722020684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60       219\n",
      "           1       0.65      0.65      0.65       253\n",
      "\n",
      "    accuracy                           0.63       472\n",
      "   macro avg       0.63      0.63      0.63       472\n",
      "weighted avg       0.63      0.63      0.63       472\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lq_copy = LearnQN.load(save_path+'hoge.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a424cde-1ff9-4a00-b522-b20432b61453",
   "metadata": {},
   "source": [
    "# 今後の方針"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd7edd-c025-4203-a84b-f429f4339ae1",
   "metadata": {},
   "source": [
    "1. モデル別収益率返却関数の実装\n",
    "2. シャープレシオ関数の実装\n",
    "SharpRatio = (PrfitRate - const)\\(Risk)\n",
    "3. early_stopping機能の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961cec2d-e383-4540-8e7e-224f93c132a4",
   "metadata": {},
   "source": [
    "# 累積収益率　比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982d4bf0-4550-4b02-be32-ddfedd52aa43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
